[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nontarget and suspect screening of organic compounds using HRMS",
    "section": "",
    "text": "1 Preface\n\nThis is a work-in-progress book to introduce the concepts of suspect and nontarget analysis (SSA/NTA) with focus on environmental analytical chemistry and to provide practical demonstrations for a workflow for SSA/NTA.\nDoes not include all the vast number of platforms, software and applications that can be used for SSA/NTA. \nIncludes the use of applications that has been developed by the author.\nBasic knowledge of R programming is a prerequisite to understand some of the codes\nThe author do not take responsibility for programs or computer crashing.\nPlease cite:"
  },
  {
    "objectID": "chapter-intro.html#terminologies",
    "href": "chapter-intro.html#terminologies",
    "title": "2  Introduction and concepts",
    "section": "2.1 Terminologies",
    "text": "2.1 Terminologies\n\nhttps://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-15-S7-S9\n\nBlank solvent\nChimeric spectra: (https://pubs.acs.org/doi/10.1021/pr1003856). Chimeras result from the isolation and simultaneous fragmentation of two or more distinct molecular ions within the isolation m/z range. Fragments from multiple parent ions will be present in the MS/MS spectrum, increasing the number of unidentified fragments in sequence database searches.\nDeconvolution: using algorithms to pair mass spectrometric peaks with chromatographic peaks to obtain pure mass spectra.\nDDA: data-dependent analysis\nDIA: data-independent analysis\nEIC: extracted ion chromatogram\nField blanks:\nHRMS: high resolution mass spectrometry\nIon statistics: From ChatGPT (20240204)\nIn mass spectrometry, ion statistics refers to the quantitative aspects of the ions produced and detected during the analysis. It involves the study and interpretation of the abundance and distribution of ions generated in the mass spectrometer.\n\nKey aspects of ion statistics include:\nIon Abundance: This refers to the relative or absolute abundance of ions at specific mass-to-charge ratios (m/z) in the mass spectrum. The intensity of peaks in a mass spectrum is a reflection of the abundance of ions with particular m/z values.\nSignal-to-Noise Ratio: Ion statistics also consider the ratio of the signal (peak intensity) to the background noise in the mass spectrum. A higher signal-to-noise ratio indicates better sensitivity and a more reliable measurement.\nPeak Shape: The shape of the peaks in the mass spectrum can provide information about the quality of the ion signal. Well-defined and symmetric peaks are generally desirable, indicating good resolution and instrument performance.\nDynamic Range: Ion statistics may also involve evaluating the dynamic range of the mass spectrometer, which is the ability to accurately measure ions over a wide range of concentrations.\nIonization Efficiency: Ion statistics may assess the efficiency of the ionization process, which is the probability that a particular analyte molecule will be ionized. Ionization efficiency can vary for different compounds and techniques.\nUnderstanding ion statistics is crucial for interpreting mass spectra and obtaining reliable quantitative information from mass spectrometric analyses. Researchers and analysts often use statistical methods to process and analyze mass spectrometry data, ensuring accurate and meaningful results.\n\nNTA: non-target analysis\nProcedural blanks:\nPseudo-quantification:\nQA sample: quality assurance sample\nSemi-quantification:\nSolvent blank\nSpace charge: From ChatGPT (20240204).\nIn the context of mass spectrometry, “space charge” refers to the accumulation of charged particles (ions or electrons) within a confined space, such as within the ionization source or in the drift region of the mass spectrometer. The presence of space charge can have significant effects on the performance and accuracy of a mass spectrometer.\n\nHere are some key points related to space charge in mass spectrometry:\nIonization Source: In the ionization source of a mass spectrometer, ions are generated from sample molecules. If the rate of ion production is high, a large number of ions can accumulate in the ionization region, leading to a space charge. This can affect the trajectory and behavior of ions as they move through the instrument.\nDrift Region: In the drift region of a mass spectrometer, where ions are accelerated and separated based on their mass-to-charge ratios (m/z), space charge effects can cause mutual repulsion or attraction among ions. This can lead to distortions in the ion trajectories, affecting the accuracy of mass analysis.\nMass Spectrometer Performance: Space charge effects can impact the performance of a mass spectrometer by causing peak broadening, reduced sensitivity, and altered ion transmission efficiency. These effects are particularly significant in high-resolution mass spectrometry where precise mass measurement is crucial.\nMitigation Strategies: Mass spectrometers are designed with strategies to minimize or compensate for space charge effects. These strategies may include the use of ion optics to focus or guide ions, the incorporation of ion traps, or the implementation of sophisticated data correction algorithms.\nCollision-Induced Dissociation (CID): In tandem mass spectrometry experiments, space charge effects can influence collision-induced dissociation. Higher ion densities may lead to increased ion-molecule collisions, affecting fragmentation patterns and the accuracy of structural information obtained.\nUnderstanding and managing space charge effects is essential for obtaining accurate and reliable results in mass spectrometry analyses. Researchers and instrument manufacturers continually work on improving mass spectrometer designs and methodologies to minimize the impact of space charge on analytical performance.\n\n_SSA__: Suspect screening analysis"
  },
  {
    "objectID": "chapter-Experimental_design.html#hypothesis",
    "href": "chapter-Experimental_design.html#hypothesis",
    "title": "3  Experimental design",
    "section": "3.1 Hypothesis",
    "text": "3.1 Hypothesis"
  },
  {
    "objectID": "chapter-Experimental_design.html#experimental-design",
    "href": "chapter-Experimental_design.html#experimental-design",
    "title": "3  Experimental design",
    "section": "3.2 Experimental design",
    "text": "3.2 Experimental design\n\nCompounds of interest?\n\nAmendable to GC and/or LC?\n\nInstrumentations available?"
  },
  {
    "objectID": "chapter-Experimental_design.html#qaqc-measures",
    "href": "chapter-Experimental_design.html#qaqc-measures",
    "title": "3  Experimental design",
    "section": "3.3 QA/QC measures",
    "text": "3.3 QA/QC measures\n\n\n3.3.1 Recovery (Extraction efficieny)\nSpiking with native before extraction to evaluate the extraction efficiency.\n\n\n3.3.2 Matrix effects\n\\[\nRecovery\\textrm{(%)} = \\frac{C_{spiked blank} - C_{unspiked blank}}{C_{added}}\n\\]\n\\[\nRecovery\\textrm{(%)} = \\frac{C_{spikedsample} - C_{unspikedsample}}{C_{added}}\n\\]\nSpiking with and after extraction to evaluate the extraction efficiency and matrix effect.\nhttps://www.future-science.com/doi/10.4155/bio-2017-0214\nTaken from (https://www.sciencedirect.com/science/article/pii/S0160412020318274#s0090)\nMethodology for the evaluation of matrix effect\nDust samples (100 mg) were extracted and cleaned up using the method described previously, and with no standards spiked before extraction (Chen et al., 2012). The final extract containing the OPEs was reconstituted in 100 μL of methanol and then aliquoted into equal volume, A and B (50 μL each). Portion A was spiked with 50 μL of standard solution of OPE mixtures at a concentration of 50 ng/mL per analyte. Portion B was spiked only with 50 μL of methanol as reference control. Finally, the aforementioned 50 μL of OPE mixture containing 50 ng/mL standards was mixed with 50 μL methanol as external standard solutions (S). Six replicate dust samples were included in matrix effect assessment. By comparing the response differences of the analytes in the sub-samples A and B to the responses of the analytes in the external standard, a matrix effect (ME) value was calculated as:\n\\[\nME\\textrm{(%)} = \\frac{A_i - B_i}{S_i} * 100\n\\]\nwhere Ai, Bi and Si are the chromatographic peak areas of the analyte (i) in sub-samples A and B and external standard solution (S), respectively. The analyte signals may be suppressed or enhanced by the co-eluted contents in the samples if ME (%) is lower or higher than 100%, respectively. The matrix effect results are shown in Table S2. If ME ∼0%, there is no matrix effect. If ME&gt; 0%, an ion-suppression occurs and, if ME &lt;0%, ion-enhancement occurs.\n\nDilute QC extracts to investigate potential matrix effects(?).\n\nField blanks.\n\nProcedural blanks.\n\nSolvent blanks.\n\nProcedural replicates.\n\nTriplicate injections.\n\nShould also inject the procedural replicates in triplicates.\n\nStandard reference material.\n\nRandomization.\n\nRetention time index standard.\n\nVolumetric internal standard added into the final extract to guard against small difference of extract volumes, as well as enable normalization of intensities/areas between samples and batches.Use e.g. 4,4’-Dibromooctafluorobiphenyl which should not be in the samples and is stable."
  },
  {
    "objectID": "chapter-Experimental_design.html#data-directory-structure",
    "href": "chapter-Experimental_design.html#data-directory-structure",
    "title": "3  Experimental design",
    "section": "3.4 Data directory structure",
    "text": "3.4 Data directory structure\nBefore starting with chemical and data analysis, you should first structure the project folder in your computer where you store all the raw and metadata. Below is a suggestion for file directory structure for your project folder. Try to use snake_case for folder and file names as space or other special characters can cause errors in various computer systems and software.\nYOUR_PROJECT_NAME\n│   Project_info.xlsx\n│\n└───Chemicals_Database\n│   │   Chemicals.xlsx\n│   │   ...\n│   │\n│   \n└───Literature\n│   │   Interesting_paper1.pdf\n│   │   ..\n│\n└───Raw_files\n│   │   File_info.xlsx\n│   │   ..\n│   │   └───LC_positive\n│   │   └───LC_negative\n│   │   └───GC_orbitrap\n│\n└───Results_Data_analysis\n│   │   Hit_list.xlsx\n│   │   Quantification.xlsx\n│   │   ..\n│   │   └───Peaklist_LC_positive\n│   │   └───Peaklist_LC_negative\n│\n└───Sample_info\n│   │   Sample_info.xlsx\n│\n└───Manuscript\n│   │   Manuscript_v1.docx\n\n    \n    \n    \nHere, the chemicals database could also be from an external folder or library. This is recommended to have a central database for all chemicals of interest such as suspect list, spectral libraries, etc."
  },
  {
    "objectID": "chapter-Experimental_design.html#sampling-design-and-collection",
    "href": "chapter-Experimental_design.html#sampling-design-and-collection",
    "title": "3  Experimental design",
    "section": "3.5 Sampling design and collection",
    "text": "3.5 Sampling design and collection\nxx \nWhat’s in a name?  Sample names/ID  Naming sample IDs might seem trivial at first but could help downstream data analysis and also to clarify your sampling design. It is important to have a uniform naming. convention and that the sample codes could also specify if a sample is a field blank, procedural blank, replicates, belong to a specific group…\n- Dont start a sample ID with a number\n- Avoid using space and special characters in the file name. Space can be replaced with underscore “_” instead."
  },
  {
    "objectID": "chapter-Experimental_design.html#collection-of-metadata",
    "href": "chapter-Experimental_design.html#collection-of-metadata",
    "title": "3  Experimental design",
    "section": "3.6 Collection of metadata",
    "text": "3.6 Collection of metadata\nMetadata is the information about data. In this particular case, it is the relevant information about our samples and chemicals of interest.\nExamples could be the location, group,"
  },
  {
    "objectID": "chapter-Experimental_design.html#chemical-analysis",
    "href": "chapter-Experimental_design.html#chemical-analysis",
    "title": "3  Experimental design",
    "section": "3.7 Chemical analysis",
    "text": "3.7 Chemical analysis\nSample order is important and should be noted in the sample information sheet. This can be important in downstream data analysis, e.g. retention time correction can be more efficiently corrected if the sample order are correctly set.\n\n3.7.1 Data recording modes\nFrom https://doi.org/10.1093/bioinformatics/btab279: “DDA strategy acquires a survey full-scan mass spectrum to select top N most abundant precursor ions for fragmentation spectra acquisition in the next several MS2 scans. (b) DIA fragments all the available precursors for MS2 scans in large predefined m/z and RT windows. he resulting MS2 are typically multiplexed and require further spectral deconvolution.\nData-independent acquisition (DIA) systematically fragments all the available precursors for MS2 scans in large predefined m/z windows over time. Due to its large precursor ion isolation window, the resulting MS2 are typically multiplexed (several molecules captured in the same spectrum) (Bilbao et al., 2015; Doerr, 2015). The post analysis of these fragmentation spectra requires advanced spectral deconvolution methods.”\nA good comparison between DDA and DIA can be seen in Guo and Huan"
  },
  {
    "objectID": "chapter-Experimental_design.html#data-analysis",
    "href": "chapter-Experimental_design.html#data-analysis",
    "title": "3  Experimental design",
    "section": "3.8 Data analysis",
    "text": "3.8 Data analysis\nxx"
  },
  {
    "objectID": "chapter-Experimental_design.html#workflow-examples",
    "href": "chapter-Experimental_design.html#workflow-examples",
    "title": "3  Experimental design",
    "section": "3.9 Workflow examples",
    "text": "3.9 Workflow examples\n\nIterative identification workflow\n\n\n\n\nWorkflow for nontarget using XX\n\n\n\n\n\n\nWorkflow for structure elucidation and identification"
  },
  {
    "objectID": "chapter-Sample_pretreatment.html#accelerated-solvent-extraction-ase",
    "href": "chapter-Sample_pretreatment.html#accelerated-solvent-extraction-ase",
    "title": "4  Sample pretreatment for nontarget and suspect screening",
    "section": "4.1 Accelerated solvent extraction (ASE)",
    "text": "4.1 Accelerated solvent extraction (ASE)\nhttps://tools.thermofisher.com/content/sfs/brochures/36395-TN209_V28_releasedJC042606.pdf\nhttp://apps.thermoscientific.com/media/cmd/rafa2013/13%20Galbiatti%20RAFA%202013.pdf\nIn some samples containing moisture or water such as soil samples or food samples (animal tissue, fruits, vegetables, and so on) an additional step may be needed either before the extraction step or as a post extraction step to remove the moisture. Sample drying can be accomplished in several ways such as air drying and oven drying prior to extraction. However, these approaches are not suited when analyzing volatile or semi-volatile components as they would be removed from the sample prior to extraction or analysis. Another common method for moisture removal is by using salts such as sodium sulfate, calcium chloride, magnesium sulfate, calcium sulfate and the like. These salts tend to associate to water molecules to form hydrated salts. Sodium sulfate for example tends to clump together when water is present.\nSodium sulfate is not suitable for in-cell moisture removal and accelerated solvent extraction. Sodium sulfate can dissolve in hot solvent to a certain extent and can precipitate downstream in some instances clogging the outlet frit, tubes and valves. Moreover, sodium sulfate becomes an aggregate hard lump upon water absorption and is not easy to process during sample preparation for in-cell moisture removal and extraction."
  },
  {
    "objectID": "chapter-Sample_pretreatment.html#ultrasonic-extraction",
    "href": "chapter-Sample_pretreatment.html#ultrasonic-extraction",
    "title": "4  Sample pretreatment for nontarget and suspect screening",
    "section": "4.2 Ultrasonic extraction",
    "text": "4.2 Ultrasonic extraction"
  },
  {
    "objectID": "chapter-Sample_pretreatment.html#direct-injection-using-large-volume-injection",
    "href": "chapter-Sample_pretreatment.html#direct-injection-using-large-volume-injection",
    "title": "4  Sample pretreatment for nontarget and suspect screening",
    "section": "4.3 Direct injection using Large Volume Injection",
    "text": "4.3 Direct injection using Large Volume Injection\nhttps://www.chromatographyonline.com/view/large-volume-injection-lc-ms-ms-methods-aqueous-samples-and-organic-extracts\nhttps://www.sciencedirect.com/science/article/pii/S0045653520331581?via%3Dihub\nhttps://enveurope.springeropen.com/articles/10.1186/s12302-023-00779-4: The high sensitivity of the current generations of LC–HRMS equipment allows for direct injection (DI) of water samples without any enrichment steps. The advantages of DI are the small water volumes required, low efforts with sample processing and less risk of background contamination during sample preparation. Minimising the sample processing results in negligible losses of compounds, as each manipulation step may discriminate against substances (e.g., by evaporation, precipitation or degradation). To obtain a sufficient sensitivity, typically large volume injections are used for DI, with volumes of 100 [26], 250 [27] or up to 650 µL [28], as no further enrichment of the sample takes place. In such cases, an adjustment of the sample composition before injection by adjusting pH and solvent addition is necessary to avoid phase dewetting or injection solvent mismatch (see Sect. “Choice of separation method”). A direct preparation of sub-samples for analysis is possible in the field by transferring individual aliquots of 1 mL into autosampler vials from a larger sampling vessel. Depending on the load of suspended particulate matter, settling of particles before aliquoting alone may be sufficient; alternatively, a filtration or centrifugation step might be necessary before analysis, with the accompanying risk of compound losses. A drawback of DI is the potential contamination of the ion source with inorganic salts that would be removed by SPE or liquid–liquid extraction (LLE). This is particularly critical for samples from estuarine or marine environments, for which even a diversion of the eluent flow away from the ion source at early retention times (RT) might not be sufficient."
  },
  {
    "objectID": "chapter-MS_preprocess.html#raw-data-conversion",
    "href": "chapter-MS_preprocess.html#raw-data-conversion",
    "title": "5  Pre-processing HRMS data",
    "section": "5.1 Raw data conversion",
    "text": "5.1 Raw data conversion\n\n5.1.1 MSConvert\n\n\n\n\n\n\n\n\n\n\nWhat\nCode\nComment\n\n\n\n\nWebsite\nhttps://proteowizard.sourceforge.io/tools/msconvert.html\nNA\n\n\nDocker: Pull from docker repo\ndocker pull chambm/pwiz-skyline-i-agree-to-the-vendor-licenses\nNA\n\n\nDocker: Help\ndocker run -it –rm chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert –help\nNA\n\n\nDocker: convert a file\ndocker run -it –rm -e WINEDEBUG=-all -v /your/data:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/file.raw\ndocker run -it –rm -e WINEDEBUG=-all -v /home/ORUNET.ORU.SE/twg/Windows_home/Raw_Data/Guo_Feng/100.RAW:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/100.raw\n\n\nDocker: convert all the files in a folder\ndocker run -it –rm -e WINEDEBUG=-all -v /your/data/path/*.RAW:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/\ndocker run -it –rm -e WINEDEBUG=-all -v ~/Windows_home/Raw_Data/Kallinge/New_analysis_20200414/test/*.mzML:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/\n\n\nuse vendor centroiding for msLevels in [1,2]\nmsconvert data.RAW –filter “peakPicking true [1,2]”\nNA\n\n\nDocker: use vendor centroiding for msLevels in [1,2]\ndocker run -it –rm -e WINEDEBUG=-all -v /home/ORUNET.ORU.SE/twg/Raw_data/Kallinge/New_analysis_20200414/centroid/:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/*.mzML –filter “peakPicking true [1,2]” –mzXML\nWorks now but need to copy files to the tla-01/02 server to be ok. From Yu Miao: The only issue is that if you convert mzML to another mzML, you will get an error about “Output filepath is the same as input filepath”. So I added ‘–mzXML’ to give another name. The only issue is that if you convert mzML to another mzML, you will get an error about “Output filepath is the same as input filepath”. So I added ‘–mzXML’ to give another name. This command contain two parts. The first part mapping your local mzML folder to the docker image’s ‘data’ folder. The second part is convert mzML files in this folder into new files.\n\n\n\n\n\n\n\n5.1.2 Waters MSe\nhttps://ccms-ucsd.github.io/GNPSDocumentation/fileconversion_waters/"
  },
  {
    "objectID": "chapter-MS_preprocess.html#peak-picking",
    "href": "chapter-MS_preprocess.html#peak-picking",
    "title": "5  Pre-processing HRMS data",
    "section": "5.2 Peak picking",
    "text": "5.2 Peak picking\n\n\n\n\n\n\nPFOS isotopic patterns\n\n\n\n\n\n\n\n\n\n\nMass traces of PFOS and labelled standards\n\n\n\n\n ## Alignment\n ## Componentization\n ## Proprietary and standardized MS data format  See: https://en.wikipedia.org/wiki/Mass_spectrometry_data_format"
  },
  {
    "objectID": "chapter-MS_preprocess.html#open-tools-for-preprocessing",
    "href": "chapter-MS_preprocess.html#open-tools-for-preprocessing",
    "title": "5  Pre-processing HRMS data",
    "section": "5.3 Open tools for preprocessing",
    "text": "5.3 Open tools for preprocessing"
  },
  {
    "objectID": "chapter-MS_preprocess.html#openms-and-toppview",
    "href": "chapter-MS_preprocess.html#openms-and-toppview",
    "title": "5  Pre-processing HRMS data",
    "section": "5.4 OpenMS and Toppview",
    "text": "5.4 OpenMS and Toppview\nxx\n https://www.youtube.com/watch?v=GuK1daIc6vo&list=PL2u38g_AG4MH7yCMF06N2VW7eZOJcglh7&index=5\n ## MSConvert xx"
  },
  {
    "objectID": "chapter-MS_preprocess.html#msnbase-and-xcms",
    "href": "chapter-MS_preprocess.html#msnbase-and-xcms",
    "title": "5  Pre-processing HRMS data",
    "section": "5.5 MsnBase and XCMS",
    "text": "5.5 MsnBase and XCMS\nxx \n\n5.5.1 XCMS\nCheck: A scalable workflow to characterize the human exposome, SI-11, https://www.nature.com/articles/s41467-021-25840-9#MOESM14\nIPO optimization\n\n\n5.5.2 CAMERA\nhttp://www.metabolomics-forum.com/index.php?topic=278.0 calcCiS: Calculate correlation inside samples That means correlation across the peak = is it really coeluting or not? It is correlation inside the sample; not inside a sample group. This means that camera goes back to the raw data and compares extracted ion chromatograms. The illutration in Carsten’s paper show this: http://pubs.acs.org/doi/abs/10.1021/ac202450g This will fail if compounds are perfectly coeluting.\ncalcCaS: Calculate correlation accross samples They are correlated if high intensity of feature A means high intensity of feature B. The study design or sample groups are not used for this information. Look at these plots. Each dot is a sample."
  },
  {
    "objectID": "chapter-MS_preprocess.html#patroon",
    "href": "chapter-MS_preprocess.html#patroon",
    "title": "5  Pre-processing HRMS data",
    "section": "5.6 PatRoon",
    "text": "5.6 PatRoon\nxx \nhttps://www.researchsquare.com/article/rs-36675/v1  https://rickhelmus.github.io/patRoon/articles/tutorial.html \nOpenMS performs peak picking and isotope grouping in one step (any idea how to turn off this?), while XCMS does not perform this step here. From Rick: For OpenMS: you can use a trick for this by setting localMZRange=0, this way OpenMS won’t be able to look for isotopes. Note that its detection was more developed for ‘natural compounds’ (eg proteomics, metabolomics) in mind, and that it isn’t really good in grouping halogenated peaks anyway.\nPatRoon Docker:\nIn linux, run:\ndocker run –rm -p 8787:8787 -u 0 -e PASSWORD=yourpasswordhere -v /home/ORUNET.ORU.SE/twg/Raw_data:/home/rstudio/Raw_data patroonorg/patroonrs /init"
  },
  {
    "objectID": "chapter-MS_preprocess.html#ms-dial",
    "href": "chapter-MS_preprocess.html#ms-dial",
    "title": "5  Pre-processing HRMS data",
    "section": "5.7 MS-DIAL",
    "text": "5.7 MS-DIAL\nMS2Dec:  Sigma window value: 0.1 - 1.0. Smaller value will avoid clustering of peaks that are far from each other (false positive grouping).\nIn GC-HRMS, try 0.8 to separate and deconvolute very closely coeluting peak in GC (+-1). These parameters should be tested with e.g. QC samples with known compounds to get best deconvolution parameter for your samples.  MS/MS abundance cut off: increase to remove background noise"
  },
  {
    "objectID": "chapter-MS_preprocess.html#output-formats",
    "href": "chapter-MS_preprocess.html#output-formats",
    "title": "5  Pre-processing HRMS data",
    "section": "5.8 Output formats",
    "text": "5.8 Output formats\n - MSnExp and XCMSnExp  - MSP  - MFG  - CSV (for both output data or metadata)"
  },
  {
    "objectID": "chapter-Suspect_screening.html#listing-suspects",
    "href": "chapter-Suspect_screening.html#listing-suspects",
    "title": "6  Suspect screening",
    "section": "6.1 Listing suspects",
    "text": "6.1 Listing suspects"
  },
  {
    "objectID": "chapter-Suspect_screening.html#suspect-scoring",
    "href": "chapter-Suspect_screening.html#suspect-scoring",
    "title": "6  Suspect screening",
    "section": "6.2 Suspect scoring",
    "text": "6.2 Suspect scoring\nhttps://www.waters.com/waters/fr_FR/Mass-Accuracy-and-Resolution/nav.htm?locale=fr_FR&cid=10091028\nMass error (ppm):\n\\[\\begin{equation}\n  ME_{ppm} = \\frac{mz_{theor} - mz_{meas}}{mz_{theor}} * 10^6\n\\end{equation}\\] \nwhere mztheor is the theoretical exact mass (in u or Da) of the isotope, and mzmeas is the measured accurate mass from the instrument.\nRMS of isotope mz error ppm:\n\\[\\begin{equation}\n  RMS_{mz} = \\sqrt{\\frac{\\sum_{i=1}^n (ME_{ppm})^2}{n}}\n\\end{equation}\\] \nAt least mz of isotopes M+1, M+2 (n &gt;= 2) should be included in the calculations to give good estimate of the average\nRMS of isotope intensities (%):\n\\[\\begin{equation}\n  RMS_{Ab} = \\sqrt{\\frac{\\sum_{i=1}^n (Ab_{theor} - Ab_{meas})^2}{n}}\n\\end{equation}\\]"
  },
  {
    "objectID": "chapter-Mass_defect.html#mdplotr",
    "href": "chapter-Mass_defect.html#mdplotr",
    "title": "7  Mass defect plots",
    "section": "7.1 MDPlotR",
    "text": "7.1 MDPlotR\nxx"
  },
  {
    "objectID": "chapter-Mass_defect.html#findhalo",
    "href": "chapter-Mass_defect.html#findhalo",
    "title": "7  Mass defect plots",
    "section": "7.2 findhalo",
    "text": "7.2 findhalo\nxx"
  },
  {
    "objectID": "chapter-Retention_time.html#lc",
    "href": "chapter-Retention_time.html#lc",
    "title": "8  Retention time index and prediction",
    "section": "8.1 LC",
    "text": "8.1 LC\nxx  \n\n8.1.1 Retip - Retention Time prediction for Metabolomics\n Webpage: https://www.retip.app/"
  },
  {
    "objectID": "chapter-Molecular_networks.html#metgem",
    "href": "chapter-Molecular_networks.html#metgem",
    "title": "9  Molecular networks",
    "section": "9.1 MetGem",
    "text": "9.1 MetGem\nThe documentation for MetGem can be found here:\nMetgem webpage: https://metgem.github.io/  Metgem handbook: https://metgem.readthedocs.io/en/latest/index.html \nMain steps for the dataset is to generate a combined msp or mgf file (such as from MS-DIAL or xcms) and import it to MetGem. Additional metadata should also be added to relate the ID of different compounds or unknowns.\n\n9.1.1 Metgem parameters\nLC https://pubs.acs.org/doi/10.1021/acs.analchem.8b03099 MS2 spectra were window-filtered by choosing only the top six peaks in the ±50 Da window throughout the spectrum. The data were filtered by removing all peaks in the ±17 Da range around the precursor m/z. The m/z tolerance windows used to find the matching peaks was set to 0.01 Da, and cosine scores were kept under consideration for spectra sharing three matching peaks at least. The molecular network was created where edges were filtered to have a cosine score of &gt;0.7. Further edges between two nodes were kept in the network if and only if each of the nodes appeared in each other’s respective top 10 most similar nodes. With regard to the t-SNE output, nodes were kept under consideration only if they share at least one cosine score above 0.6 with others (“at least one cosine score above 0.6” parameter). The number of iterations, perplexity, learning rate, and early exaggeration parameters were set to 1000, 6, 200, and 12, respectively. The Barnes-Hut approximation was activated using a θ angle of 0.5°. These values were initially used as a first approximation based on the scikit-learn t-SNE package default parameters. Except for the perplexity that has been reduced from 30 to 6, which was more adapted for small data sets, all these parameters looked appropriate as very well-defined clusters were clearly perceptible and the data organization was consistent with the observed fragmentation patterns.\nGroup mapping files can be used in MetGem to create groups within sample datasets depending on any observation or user’s specification (biological activity, origin of a sample, taxonomy, analytical details or whatever). These groups can further be mapped in both MNs and t-SNE graphs to ease the visualization and the analysis of data. Group mapping files must be submitted as .txt files and follow the GNPS-style format: GROUP_Active=Sample1.mzXML;Sample2.mzXML GROUP_Inactive=Sample3.mzXML;Sample4.mzXML GROUP_Blanks=Blank1.mzXML GROUP_Samples=Sample1.mzXML;Sample2.mzXML;Sample3.mzXML;Sample4.mzXML GROUP_Active signifies that this group contains the two samples 1 and 2, MetGem will then sum up the peak area values of these two samples for each feature and display the result in a new dedicated “Active” column in the metadata table. Note that a sample can be assigned to several groups and at least one sample must appear in a specified group.\n\n\n\n\n\nDescription of the parameters available for the t-SNE visualization\n\n\n\n\nSmall datasets: up to 2 000 nodes\nMedium Datasets: 2 000 to 10 000 nodes\nLarge Datasets: &gt; 10 000 nodes\nFor more information, please see : https://lvdmaaten.github.io/tsne/ ; http://scikit-learn.org/stable/modules/manifold.html#t-sne.\nGC data \n\nFrom MSDIAL: Export “Alignment result”. check “Raw data matrix (Area)” and “Representative spectra”. Check “Filter by..blank samples”. Export format “msp”.\n\nCopy the .txt file to excel. Copy the content to a new sheet. Remove top rows, select only: “Alignment ID”, “Metabolite name”, “Average Rt(min),”Quant mass”, and the areas of selected samples. Save sheet as tab delimited file (.txt). The number of rows should be the same as the number of individual queries in the msp file.\n\nNOTE: For GC orbitrap data: - When importing metadata, have the “index column” empty, instead of Alignment ID. Otherwise ID will be incorrectly assigned. - check the treat as MS1 data\n- m/z tolerance: 0.01 Da\n- Minimum matched peaks: 6\n- uncheck the “Keep peaks outside of the…” box\n- uncheck the “Keep each peak in top…” or use a low setting such as “top 10 in the 5 Th window”\n- Check the “Keep peaks above 1% of maximum”\nCan play around with the “% peak of maxmum” and “top n” parameters to get best parameters for your purpose. Use annotated compounds or a standards msp library to check related compounds and/or metabolites and parents.\n\nNetwork parameters: cosine score: 0.65\nt-sne parameters: cosine score: 0.6\n\nText from authors GC method: A new option was added to the input data file dialogue. When this option is activated, input spectra are treated as MS1, and thus, the parent m/z ratio is fully ignored.\nThe molecular networks were created using MetGem 1.2.2 software (https://metgem.github.io/). EI-MS spectra were window filtered by choosing only the top 6 peaks in the ±50 Da window throughout the spectrum. Cosine scores were calculated using a m/z tolerance of 0.3 Th. Networks were then created where edges were filtered to have a cosine score above 0.7 (or 0.75 in the case of GC-EI-MS data from perfumes) and more than six matched peaks. Furthermore, edges between two nodes were kept in the network if and only if each of the nodes appeared in each other’s respective top 10 most similar nodes. The library spectra were filtered in the same manner as the input data."
  },
  {
    "objectID": "chapter-Molecular_networks.html#gnps",
    "href": "chapter-Molecular_networks.html#gnps",
    "title": "9  Molecular networks",
    "section": "9.2 GNPS",
    "text": "9.2 GNPS\nhttps://gnps.ucsd.edu/\nhttps://ccms-ucsd.github.io/GNPSDocumentation/fileupload/\nCarbon marker table: https://ccms-ucsd.github.io/GNPSDocumentation/gc-ms-library-molecular-network/"
  },
  {
    "objectID": "chapter-library_search_annotation.html#matchms",
    "href": "chapter-library_search_annotation.html#matchms",
    "title": "10  Spectral libraries",
    "section": "10.1 MatchMS",
    "text": "10.1 MatchMS\nhttps://matchms.readthedocs.io/en/latest/"
  },
  {
    "objectID": "chapter-library_search_annotation.html#in-silico-fragmentation",
    "href": "chapter-library_search_annotation.html#in-silico-fragmentation",
    "title": "10  Spectral libraries",
    "section": "10.2 IN SILICO FRAGMENTATION",
    "text": "10.2 IN SILICO FRAGMENTATION\nThere are several openly available models that have recently been published to predict the fragmentation patterns of GC-EI MS.\n\n10.2.1 Metfrag\n\n\n10.2.2 Sirius CSI FingerID\n - Need to convert msp to mgf format\n- If generating mgf file, then it needs to be saved as UTF-8 (UTF-8 with BOM doesnt work with Sirius)\n- For GC data:\nBEGIN IONS\nPEPMASS=\nNAME=\nMOLECULARFORMULA=\nCHARGE=1\nADDUCT=[M]+\nMSLEVEL=2\nmz “tab” intensity\nEND IONS\nwhere the “tab” is tab key between the mz and intensity value pair\nwhen using MSLEVEL=2, then isotopes of precursor ion will not be matched. IF needed then\n\n\n10.2.3 CFM-ID\nIn silico fragmentation:\nHelp file: https://sourceforge.net/p/cfm-id/wiki/Home/\nUse instructions:\n\nIf you are using EI-MS (GC-MS) data, please use the ei_ms_model provided.\n\nNote that lpsolve55.dll must also be included in the same directory as the executables. This file can be found in the development version of LPSolve (e.g. lp_solve_5.5.2.0_dev_win32.zip), which can be downloaded from https://sourceforge.net/projects/lpsolve/files/lpsolve/5.5.2.5/lp_solve_5.5.2.5_dev_win32.zip/download.\n\nCfm-predict\nCOMMAND:\ncfm-predict.exe &lt;smiles_or_inchi_or_file&gt; &lt;prob_thresh&gt; &lt;param_file&gt; &lt;config_file&gt; &lt;annotate_fragments&gt; &lt;output_file_or_dir&gt; &lt;apply_postproc&gt; &lt;suppress_exceptions&gt;\n\nEXAMPLE (naphthalene):\ncfm-predict.exe InChI=1S/C10H8/c1-2-6-10-8-4-3-7-9(10)5-1/h1-8H 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp\n\nEXAMPLE (.txt file as input):\ncfm-predict.exe D:/Program/cfm-id-2.4_win32/test/input.txt 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp"
  },
  {
    "objectID": "chapter-library_search_annotation.html#neims",
    "href": "chapter-library_search_annotation.html#neims",
    "title": "10  Spectral libraries",
    "section": "10.3 NEIMS",
    "text": "10.3 NEIMS\nHelp files: https://github.com/brain-research/deep-molecular-massspec"
  },
  {
    "objectID": "chapter-library_search_annotation.html#deepei",
    "href": "chapter-library_search_annotation.html#deepei",
    "title": "10  Spectral libraries",
    "section": "10.4 DeepEI",
    "text": "10.4 DeepEI\nHelp files: https://github.com/hcji/DeepEI\nhttps://github.com/hcji/DeepEI/blob/master/Usage.ipynb"
  },
  {
    "objectID": "chapter-library_search_annotation.html#qcxms",
    "href": "chapter-library_search_annotation.html#qcxms",
    "title": "10  Spectral libraries",
    "section": "10.5 QCxMS",
    "text": "10.5 QCxMS\nThis program only runs on LINUX SERVER.\n\nCheck QCxMS online manual for details\nCheck PlotMS online manual\n\nPREPARATION - Download the latest version of QCxMS at: https://github.com/qcxms/QCxMS/releases/\n- Download the lates PlotMS version at: https://github.com/qcxms/PlotMS/releases/ and copy to the same folder as QCxMS\n- Copy the .XTBPARAM folder and the .mass_raw.agr files to /home/ORUNET.ORU.SE/twg/\n\nPrepare a file with the equilibrium structure of your desired molecule. Important: This file has to be named coord (without file extension) and should have the TURBOMOLE coord format (tmol).\n\n1.1. Simple: download the 3D conformer structure in pubchem in sdf format and then convert using openbabel -&gt; tmol. Remove the file extension .tmol so the file name is only coord without any extension\n1.2. Optimized 3D conformer according to steps by Wang et al:\n- Download the 3D conformer in Pubchem as sdf. - Import into Avogadro (https://avogadro.cc/). If 3d-struture is not available, then use “build”-&gt; “insert SMILES”. This will take longer time to optimize.\n- Use the auto-optimize tool (https://avogadro.cc/docs/tools/auto-optimize-tool/); Force field (MMFF94), Steps per update (10), Steepest Descent. When dE=0 then it is optimized and you can save as a .mol file.\n- Use Openbabel to convert .mol to .tmol file. Rename as coord without the extension.\n\nPrepare an input file called “qceims.in”. For the input options, see the online manual or the qceims.in file in the examples folder. If no such file is prepared, default options are: run GFN1-xTB with 25 times the number of atoms in the molecule trajectories (ntraj).\n\nTO RUN QCEIMS\nOpen bash\n\nEnable overwriting files in your Linux:\n\nset +o noclobber\n\nPlace the executables into your $HOME/bin directory or path. Easiest is to enable the QCxMS executables in the path as seen below (replace the names if the QCxMS executables are in another folder):\n\nCheck: https://linuxize.com/post/how-to-add-directory-to-path-in-linux/\necho $PATH\n\nexport PATH=/home/ORUNET.ORU.SE/twg/QCxMS/:/home/ORUNET.ORU.SE/twg/bin:/home/ORUNET.ORU.SE/twg/.local/bin:/bin:/usr/bin:/opt/thinlinc/bin:/usr/local/bin:/usr/bin/X11:/sbin:/usr/sbin:/usr/local/sbin:/snap/bin:/opt/thinlinc/bin:/opt/SPAdes/SPAdes-3.13.0-Linux/bin:/opt/mauve/mauve_snapshot_2015-02-13:/opt/parsnp/Parsnp-Linux64-v1.2:/opt/prokka/prokka-master/bin:/opt/artemis/artemis\n\ngo to your folder, e.g:\n\ncd QCxMS/example/ethanol\nRun:\nqcxms\nRun qcxms again and check the ouput if all is ok.\n\nExecuting production runs. If you want to run QCxMS locally, use the pqcxms script with -j number of parallel jobs and -t number of OMP threads:\n\npqcxms -j &lt;integer&gt; -t &lt;integer&gt; &\n\ne.g: pqcxms -j 6 -t 4  &\nMake sure you add the &at the end so you can return to the prompt by hitting Enter.\nYou can check how any CPUs and threads are used by opening a new console and type top and then press 1 followed by t for visual bar chart.\nCheck the status of your QCxMS run by changing to your working directory (first press Enter to get back the prompt) and typing\ngetres\n, which will provide an output of the form:\nXXX runs done and written to tmpqceims.res/out\nwhich gathers the runs already finished (creates tmpqceims.res and tmpqceims.out). The final results are on qceims.out and qceims.res\n\nSKIP: this doesnt work anymore with the new QCxMS version 6. (Download an exp. EI-MS from the NIST if available and copy it to the working dir as exp.dat; take the JCAMP-DX format from their web page).\nget spectrum by\n\nplotms\nSKIP: and plot it with xmgrace mass.agr. the file “.mass.agr” should be in your home dir. plotms reads by default &lt;qceims.res&gt; or by plotms -f &lt;name_of_res_file&gt; any other res file. Check the consistency of the total charge.\n\nClean the csv file to remove low abundance ions and then copy the m/z and rel abundance to an msp file. Run MS-LIMA to compare the spectra.\n\nADDITIONAL_OPTIMIZATION: if the ratio of fragment to M+ signals is too large decrease the IEE by increasing the parameter ieeatm (default is 0.6 eV/atom) by inserting\nieeatm  &lt;value&gt;\nin the qceims.in file and do the parallel run again (requires an additional qcxms pre-run).\n\nif the IEE is ok, increase ntraj to get better statistics and re-run (note: qcxms.res is appended so delete it at this point).\n\nVERY IMPORTANT: EVERY CHANGE IN THE INPUT REQUIRES A RUN OF QCEIMS IN THE WORKING DIR BEFORE THE PARALLEL SCRIPT IS STARTED IN ORDER TO BE IN EFFECT!\n\ntrajectories are in TMPQCEIMS/TMP. they are numbered by the run and the ion tracking number. (something like gmolden TMPQCEIMS/TMP.$1/trj.$1.$2 gives trajectory $1, track $2)\nfor more QCEIMS code options (model parameters) see manual\n\nuseful options for qceims:\n-c : check IEE but do nothing (requires M trajectory) -p : normal production (fragmentation) mode. Possible in any existing TMPQCEIMS/TMP.$1 directory. -eonly : use the requested QC (as specified in qceims.in) and do a single-point energy -e0 : same as above, charge = 0 -e1 : same as above, charge = 1 -qcp  : string = path to the QC code /usr/local/bin is default)\nother important options in &lt;qceims.in&gt;:\nip- ntraj  ieeatm  iseed  (random number initialization to start different runs)\nVizualize trajectories\nExport VMDMovie folder to Path, go first to the folder with VMDMovie then enter:\nexport PATH=$PATH:$(pwd)\nGo to the working directory and enter:\nmsmovie X Y\nto load the trajectory TMPQCEIMS/TMP.X/trj.X.Y. For instance, msmovie 1 1 loads the first trajectory of the first folder. Some adjustments according to personal preferences for movie-making may have to be made in these scripts.\nIn silico photodegradation product generation\nUse the US EPA CTS: Chemical Transformation Simulator to predict photodegradation products by the Generate Transformation Products Module.\n- Enter the lookup structure.\n- Select: User selected -&gt; Direct Photolysis.\n- Choose number of generations of transformation products."
  },
  {
    "objectID": "chapter-library_search_annotation.html#library-search",
    "href": "chapter-library_search_annotation.html#library-search",
    "title": "10  Spectral libraries",
    "section": "10.6 LIBRARY SEARCH",
    "text": "10.6 LIBRARY SEARCH\nxx"
  },
  {
    "objectID": "chapter-library_search_annotation.html#reading-mgf-files-in-r",
    "href": "chapter-library_search_annotation.html#reading-mgf-files-in-r",
    "title": "10  Spectral libraries",
    "section": "10.7 Reading mgf files in R",
    "text": "10.7 Reading mgf files in R"
  },
  {
    "objectID": "chapter-library_search_annotation.html#lib2nist",
    "href": "chapter-library_search_annotation.html#lib2nist",
    "title": "10  Spectral libraries",
    "section": "10.8 LIB2NIST",
    "text": "10.8 LIB2NIST\nUse LIB2NIST to convert combined msp file to NIST library. Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass since the GUI tool only convert to nominal mass) NOTE TO SELF: CHECK IF THIS IS TRUE. See command line help file for arguments.\nNOTE TO SELF: NEED TO CHECK IF IT IS POSSIBLE TO INCLUDE Retention index. Check: https://www.nist.gov/system/files/documents/srd/NIST1aVer22Man.pdf (Section Import and Export of Retention indices with a spectrum)\nConvert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass). See command line help file for arguments.\nIN WINDOWS: open ‘cmd’, go to the folder where LIB2NIST is and type:\nCOMMAND:\nlib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt;\nEXAMPLES:\nlib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\RECETOX_GC-EI_MS_20201028.msp D:\\Program\\NIST14\\ =RECETOX_GC-EI_MS_20201028\nEXAMPLES:\nlib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\2021-05-28_MTM_HRMS_RECETOX_THERMO.msp D:\\Program\\NIST14\\ =MTM_HRMS_RECETOX_THERMO_20210528"
  },
  {
    "objectID": "chapter-library_search_annotation.html#mspepsearch",
    "href": "chapter-library_search_annotation.html#mspepsearch",
    "title": "10  Spectral libraries",
    "section": "10.9 MSPepSearch",
    "text": "10.9 MSPepSearch\nUse MSPepSearch to query NIST msp output against NIST library and own library\nEXAMPLES:\nMSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 10 /OnlyFound /HITS 5 /LIB D:\\Raw_data\\Dust_Florian\\GC\\test\\Mylib /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\input.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv /OutMW\nMSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 100 /OnlyFound /HITS 5 /LIB D:\\PROGRAM\\NIST14\\MTM_HRMS_RECETOX_THERMO_20220518 /INP D:\\Projects\\Mexico_Air\\NIST_Mexico.msp /OUTMGF D:\\Projects\\Mexico_Air\\test\\test.mgf /OUTTAB D:\\Projects\\Mexico_Air\\test\\test.tsv\nMSPepSearch64.exe Gusviqh /ZI 0.01 /ZIPPM 10 /MPPM 10 /MzLimits 50 -1 /MinMF 500 /OnlyFound /HITS 5 /LIB D:\\PROGRAM\\NIST14\\MTM_HRMS /INP D:\\Projects\\Mexico_Air\\NIST_Mexico.msp /OUTMGF D:\\Projects\\Mexico_Air\\test\\test.mgf /OUTTAB D:\\Projects\\Mexico_Air\\test\\test.tsv\nMSPepSearch64.exe Gusviqh /ZI 0.01 /ZIPPM 10 /MPPM 10 /MzLimits 50 -1 /MinMF 500 /OnlyFound /HITS 10 /LIB D:\\Program\\NIST14\\MTM_HRMS_RECETOX_THERMO_20220518 /INP D:\\Raw_data\\Dust_Florian\\GC\\Raw_data\\mzML\\Spectrum_0_202111221149_NIST.msp /OutChemForm /OUTMGF D:\\TEST\\MSPepsearch\\test.mgf /OUTTAB D:\\TEST\\MSPepsearch\\test.tsv\nMore info on commands on: https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.9b03415/suppl_file/ac9b03415_si_001.pdf"
  },
  {
    "objectID": "chapter-library_search_annotation.html#annotation",
    "href": "chapter-library_search_annotation.html#annotation",
    "title": "10  Spectral libraries",
    "section": "10.10 Annotation",
    "text": "10.10 Annotation\n\n10.10.1 High resolution mass filtering\n\n10.10.1.1 MFAssignR\n\n\n10.10.1.2 https://github.com/RECETOX/MSMetaEnhancer"
  },
  {
    "objectID": "chapter-data_post_processing.html#data-vizualization",
    "href": "chapter-data_post_processing.html#data-vizualization",
    "title": "11  Data post-processing",
    "section": "11.1 Data vizualization",
    "text": "11.1 Data vizualization\n\n11.1.1 Hilbert curve\nhttps://github.com/jokergoo/HilbertCurve\n\n\n11.1.2 Cloud plot\n\n\n11.1.3 Classyfire\nNOTE: better to use Classyfire batch instead of below script: https://cfb.fiehnlab.ucdavis.edu/"
  },
  {
    "objectID": "chapter-data_post_processing.html#hierarchical-clustering",
    "href": "chapter-data_post_processing.html#hierarchical-clustering",
    "title": "11  Data post-processing",
    "section": "11.2 Hierarchical clustering",
    "text": "11.2 Hierarchical clustering\nNOTE: check how to extract outliers from the matrix"
  },
  {
    "objectID": "chapter-Conversion_HRMS_RawData.html#MSConvertGC",
    "href": "chapter-Conversion_HRMS_RawData.html#MSConvertGC",
    "title": "12  Conversion of raw data from HRMS vendor format to open format",
    "section": "12.1 GC orbitrap HRMS: convert .raw data to .mzML using MSconvert",
    "text": "12.1 GC orbitrap HRMS: convert .raw data to .mzML using MSconvert\n\nThe first step is to convert the vendor software format to the open mass spectrometric data format mzML. We use MSConvert to perform this. After installing Proteowizard, open the MSConvert program. Most vendor software record the mass spectra in profile mode, but data processing of this format is usually very time consuming as well as producing very large files. Therefore, during file conversion we will also perform centroiding to make data processing faster as well as reducing the size of the mzML file.\n\n\nOpen MSConvert.\n\nClick “Browse” and choose the raw file(s) you want to include and add.\n\n\nChoose mzML as the output format. Make sure the “Output Directory” is correctly set to the folder you want to store the mzML file. For this library task, you can directly choose the “/MTM_HRMS_LIB/MSDIAL_PROJECT” in the library folder as temporary storage.\nIn the “Filters” drop down menu, select “Peak Picking”. For “Algorithm”, use “Vendor” for most raw files. Choose appropriate MS Levels you want to include. Use “1 -” to choose all MS levels. For GC data, this is fine (since we are using EI there is only MS1). Press add and then make sure to move the “peakPicking” filter as the first filter as seen in below figure.\nIf you have many files, it would be wise to increase the “Files to convert in parallel” to speed up the process. However, this depends on your computer processing power the number of cores it has. The other parameters should be set as seen in below Figure @ref(fig:MSConvert).\n\n\n\n\n\n\nMSConvert\n\n\n\n\nNow you can proceed with the conversion by clicking “Start”.\nAfter you have finished with the conversion, copy the mzML file(s) to the designated folder in MTM_HRMS_LIB/2_mzML_data/../ (where “..” is the folder depending on your instrument type and analysis mode). If you want, you can now delete the original .raw file if you want to save disk space (although a copy should be available in the analysis instrument or on the server)."
  },
  {
    "objectID": "chapter-Conversion_HRMS_RawData.html#MSConvertunifi",
    "href": "chapter-Conversion_HRMS_RawData.html#MSConvertunifi",
    "title": "12  Conversion of raw data from HRMS vendor format to open format",
    "section": "12.2 LC-HRMS: convert the raw data file from unifi to mzML using MSconvert",
    "text": "12.2 LC-HRMS: convert the raw data file from unifi to mzML using MSconvert\n\nThe first step is to convert the vendor software format to the open mass spectrometric data format mzML. We use MSConvert to perform this. The Proteowizard should be already installed in the computer connected the G2 XS qtof instrument. In Windows, search for MSConvertin the search bar and open it. Click on the “Browse network resource” and choose UNIFI. A new window will open which you will see the folders where all raw files are located. Choose the files you want to convert (it might take a couple of minutes before all files are loaded if the folder contain a lot of analysis files). After selecting the files, click on “Open” button.\nIf you only choose one file, then you should also click on “Add” to add the raw file to the list (see XX). Choose mzML as the output format. Make sure the “Output Directory” is correctly set to the folder you want to store the mzML file.\n\nMost vendor software record the mass spectra in profile mode, but data processing of this format is usually very time consuming as well as producing very large files. Therefore, during file conversion we will also perform centroiding to make data processing faster as well as reducing the size of the mzML file.\n\nIn the “Filters” dropdown menu, select the “Peak Picking. For”Algorithm”, use “Vendor” for most raw files. Choose appropriate MS Levels you want to include. Use “1 - 2” to choose all MS1 (channel 1, low energy scan) and MS2 (channel 2, high energy scan). For the G2 XS qtof, there is also channel 3 which is the lock mass and not needed in this case. Click on “Add” and then make sure to move the “peakPicking” filter as the first filter as seen in below Figure @ref(fig:LCMSConvert).\nIf you have many files, it would be wise to increase the “Files to convert in parallel” to speed up the process. However, this depends on your computer processing power the number of cores it has. The other parameters should be set as seen in below Figure @ref(fig:LCMSConvert).\n\nNOTE: Unfortunately, the conversion to mzML files takes a very long time for unifi files in the current computer and you should convert max 2 files. We might find a better solution for this problem in the future.\n\n\n\n\n\nMSConvert\n\n\n\n\nNow you can proceed with the conversion by clicking “Start”.\nAfter you have finished with the conversion, copy or move the mzML file(s) to the designated folder in MTM_HRMS_LIB/2_mzML_data/LC_ESI../ (where “..” is the folder depending on the analysis mode, POS or NEG)."
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_GC.html#analyze-the-standards-using-hrms",
    "href": "chapter-HRMS_Spectral_Lib_GC.html#analyze-the-standards-using-hrms",
    "title": "13  MTM HRMS Library: GC-HRMS",
    "section": "13.1 Analyze the standards using HRMS",
    "text": "13.1 Analyze the standards using HRMS\nIt is recommended to analyze single standards but mixtures are also feasible to analyze if the analytes are not coeluting too close to each other. The deconvolution algorithm of MS-DIAL is able to distinguish between two peaks that are closely eluted but still have slightly different retention times and peak shapes. Around 1 ppm is sufficient to get a good peak shape and ion intensities in the GC-orbitrap HRMS, but this depends of course on each specific compound. If you don’t see any peaks, then check if there is any solubility issues or that the analytes are GC compatible (boiling point, polarity,..).\nYou should also inject a solvent blank to perform blank subtraction later in MS-DIAL."
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_GC.html#convert-the-raw-data-file-from-gc-hrms-analysis-to-.mzml-using-msconvert-for-unifi-conversion-see-section-refmsconvertgc",
    "href": "chapter-HRMS_Spectral_Lib_GC.html#convert-the-raw-data-file-from-gc-hrms-analysis-to-.mzml-using-msconvert-for-unifi-conversion-see-section-refmsconvertgc",
    "title": "13  MTM HRMS Library: GC-HRMS",
    "section": "13.2 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi conversion, see section @ref(MSConvertGC)",
    "text": "13.2 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi conversion, see section @ref(MSConvertGC)\nFollow the steps in section @ref(MSConvertGC)"
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_GC.html#fill-in-the-standard-infosheet",
    "href": "chapter-HRMS_Spectral_Lib_GC.html#fill-in-the-standard-infosheet",
    "title": "13  MTM HRMS Library: GC-HRMS",
    "section": "13.3 Fill in the standard infosheet",
    "text": "13.3 Fill in the standard infosheet\nIn the main folder, choose one of the standard information sheets depending on whether you used LC or GC and the ionization mode. The content of the information sheet looks slightly different depending on LC or GC. Copy the chosen infosheet to the “1_Standard_infosheets” folder. In that folder, rename the copied infosheet to the new MTM id as mentioned in previous section.\nThe infosheet is organized in accordance to the format used by Massbank Europe. A description on the Massbank record format can be found here. It is important that you do not change any of the titles in the first column in the infosheet, as the format requirement is quite strict. Also, try not to copy text from one cell to another as it might change the underlying format of the cells (if you think you made an error, copy the template and redo again).\nThe rows that are in bold are information that are mandatory to fill in.\nThe “ACCESSION” row is the MTM id.\nThe “RECORD_TITLE” will be automatically generated based on the information you filled in so you should not fill this row.\n“COMMENT: centroided mzML file name” is for internal purposes and refers to the name of the mzML file you converted and copied to the “MTM_HRMS_LIB/2_mzML_data/../” folder.\n“COMMENT: msp file name” is automatically generated and will be used later to name the msp file.\n“COMMENT: CONFIDENCE” refers to how confident you are of the identification of your standard according to the “Schymanski scale”. Leave it as “Reference Standard (Level 1)”, unless there are standards where you cannot distinguish or identify between different isomers in a standard. In this case, you should use “Level 3”. An example is “Technical mixture (Level 3)”, where we analyzed a technical standard (usually &lt;90% purity) and several isomeric peaks can be seen in the chromatogram. In this case, I usually individually register each isomer in its own infosheet (spectral peak patterns will look very similar with slight differences and retention time is different).\n“COMMENT: QUANTMASS”. This is the quantification mass for MSDIAL to find for EIC of model ions to compare different samples and groups. Choose the monoisotopic ion if possible or the highest peak at the higher end of the mass range. Copy this m/z directly from the msp file so the decimals matches.\n“CH$NAME:” occurs twice which means you have to input two different names for the compound in the standard, because a compound can have different names. It could be the common name specified in PubChem, the IUPAC name, trade name or the abbreviation.\n“CH$IUPAC” is the InChI and always starts with “InChI=”. You can find all these information for the compound by searching in PubChem.\nFor GC compounds, you also need to fill in the COMMENT: QUANTMASS, AC$CHROMATOGRAPHY: KOVATS_RTI and AC$CHROMATOGRAPHY: RETENTION_TIME. These will be made available later in MS-DIAL.\nThe other rows should be quite straightforward to fill in. If you use the same method for many standards, then you can save a copy of an infosheet to use as a method template, while only updating information for each specific compound: ACCESSION, DATE, COMMENT: centroided mzML file name, CH$NAME, CH$NAME, CH$FORMULA, CH$EXACT_MASS:, CH$SMILES:, CH$IUPAC:, CH$LINK: CAS, CH$LINK: INCHIKEY\nThe AC$CHROMATOGRAPHY: RETENTION_TIME row will be obtained later using MS-DIAL.\nNow that you have filled in most information about the compound, we can proceed to process the mzML file to extract the spectra using MS-DIAL (although you can also first process the mzML files and then fill in the information afterwards)."
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_GC.html#use-ms-dial-to-perform-spectral-deconvolution-and-generate-spectra-for-each-compound",
    "href": "chapter-HRMS_Spectral_Lib_GC.html#use-ms-dial-to-perform-spectral-deconvolution-and-generate-spectra-for-each-compound",
    "title": "13  MTM HRMS Library: GC-HRMS",
    "section": "13.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound",
    "text": "13.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound\nThe graphical user interface of MS-DIAL takes some time to get used to since it is centered around detected peaks. It is important that you choose the correct parameters in the beginning since the parameters can affect the peak detection and alignment, or else you need to redo the data preprocessing again which could take long time if you are analyzing a lot of samples. When you run a large number of real samples, it is recommended to first optimize the parameters using e.g. QC samples. In this case where we analyze standards, then the default parameters with some instrument specific parameters can be used. These are found in the subfolder MSDIAL_PROJECT/MSDIAL_params/. If you want to know more details about data processing using MS-DIAL, please check the MS-DIAL online tutorial.\nThe below steps are based on the workflow for GC-EI orbitrap data described by Price et al..\n1. In the File menu, start a new project. You must choose a file path where the mzML file(s) are located. When the data analysis is finished, several files associated with the analysis is created in the same folder. Depending on GC or LC analysis, then different parameters needs to be selected. Below Figure @ref(fig:MSDIALStartup) shows parameters for GC analysis. GC-EI is a hard ionization and we also centroided the mzML file so these paramters needs to be specified.\n\n\n\n\n\nStarting a new project for GC analysis\n\n\n\n\nClick on the “Advanced: add further meta data” tab. The information for different instruments in our lab can be found in the file “/MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/Metadata.txt”. If your instrument is not present then you can input these by yourself. This metadata is optional but the information will be added to the msp file later so please fill this in.\nWhen you are finished, click on next.\n2. Click on the browse button and then you will select the files to process. The default file format is .abf but we want to process .mzML so choose this file format instead. You will now see the mzML file(s) in your working directory. If you want to process multiple files use Shift/Ctrl + select. Make sure your standards are designated as “Sample”. You should include a solvent blank which will be designated as “Blank”. The other columns are for post processing and not important for this spectral database workflow. You can learn more about these in the tutorial.\n\n\n\n\n\nChoosing files\n\n\n\n\nClick on next to the Analysis parameter settings.\n3. The following instructions are for GC-EI orbitrap data, but the other processing methods are similar. Click on the “Load” button and select the “GC_EI_Orbitrap.med2” (for GC-EI-orbtrap files) file located in the “/MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/” folder. This will load the preset parameters for this instrument. You can set the parameters that are suitable for your specific analysis. Click on the “Advanced” tab and you can also choose how many samples (threads) to process in parallel. Continue with the “Peak detection” tab and set an appropriate minimum peak height. This is instrument specific and also depends on the concentration of the analytes. If the “Accurate MS” box is not checked, then select it. Below Figure @ref(fig:MSDIALPeakdetection) shows the parameters for the GC-EI orbitrap. The smoothing levels and width can be set as 3 and 10 respectively for GC analysis.\n\n\n\n\n\nPeak detection parameters\n\n\n\n\nContinue to the “MS1Dec” tab.\n4. The sigma window value is an important parameter which determines the efficiency of the deconvolution algorithm. The parameter depends on the instrument and Figure @ref(fig:MSDIALMS1Dec) shows the recommended ones for the GC orbitrap analysis of standards. From the online tutorial: “The sigma window value is highly affected by the resolution of deconvolution. A higher value (0.7-1.0) will reduce the peak top resolutions, i.e. the number of resolved chromatographic peaks will be decreased. On the other hand, a lower value (0.1-0.3) may also recognize many noise chromatographic peaks. In addition, you may set a cutoff value to reduce the MS noises (see Section 3-3 of Chapter 3 of the online manual). This is the same as LC/MS part.”\n\n\n\n\n\nMS1Dec parameters\n\n\n\n\nContinue to the “Identification” tab.\n5. If you process GC data, we mainly want to “Use retention index (RI)”. If the below “Set” button cannot be clicked, then first click on the “Use retention time (min)” button and the back again to the “Use retention index (RI)” button and then you will be able to click on the “Set” button next to the Index file (Figure @ref(fig:MSDIALIdentification)). The “Index type” should be set to “Alkanes” since we analyzed an alkane mix. If you are using LC, then you should choose “Use retention time (min)”, since no retention index mix is used (yet). After you clicked the Set button, you will then choose a retention index file that include the retention time (in minutes) of the different alkanes in the mixture. A template of how the format should be can be found in the file “/MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/xxxxxx_RTI_MSDIAL.txt”. Adjust the retention time depending on your specific analysis after checking the chromatogram of the alkane mix. An example of the retention times of alkane mix can be found in the “/MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/AlkaneMixRT.pptx” file. After you chosen the RTI file, right click on the mouse on the cell and choose autofill.\n\n\n\n\n\nIdentification parameters\n\n\n\n\nThe other parameters are not important for this standard library generation workflow and you can click on the “Alignment” tab. The purpose of alignment is to align all individual samples so the retention times for the same for the same compound between all samples. This is because the chromatographic retention time will slightly change between runs and batches and needs to be aligned for downstream data processing. You do not need to pay attention to this tab for the spectral library purpose. continue to the last tab “Filtering”.\nSelect the “Remove features based on blank information”and choose 5 fold change. This will remove any features that are lower than five times the blank samples (solvent blank in this case).\n\n\n\n\n\nFiltering parameters\n\n\n\n\nNow you are done and click on “Finish”. Sample processing might take a while depending on the processing power and the number of samples.\nAfter the peak detection and deconvolution process has finished, you should see below screen.\n\n\n\n\n\nx\n\n\n\n\nDouble click on the sample name where your standard was analyzed (see 1 in Figure @ref(fig:MSDIALSample)). Your screen will be switched to the “Peak spot viewer” tab. Each detected component will be seen as a downward pointing triangle (see 2 in Figure @ref(fig:MSDIALSample)). You should zoom in to the peak by moving you pointer to below the x-axis and scroll to zoom in the retention time axis (3). You should now be able to see the peak more clear and click on the peak as seen in 4 in Figure @ref(fig:MSDIALPeak).\n\n\n\n\n\nx\n\n\n\n\nYou can then see the EIC (5) of the chosen peak to check if the peak shape is good. The extracted spectrum is shown in (6), and the retention time and retention index can be seen in (7). This is the deconvoluted spectrum and you can see the peak shape of the ion fragments with the highest intensities by choosing the “EI chrom” tab (8) which allows you to see if the deconvolution process has been successful (9). A note here is that the EIC shown in (5) is usually for the most intense spectral peak in the deconvoluted spectrum. When you feel that the quality is satisfactory, then you can export the spectrum to MS-FINDER by clicking on the “MS FINDER search” button (10).\n\n\n\n\n\nx\n\n\n\n\nADD INFO ABOUT MS-FINDER PARAMETERS\nIn the new MS-FINDER window, go to “Settings” -&gt; “Parameter settings”. In the “Methods” tab, check the “Formula prediction..” and “Use internal experimental..” options. The rest should be unchecked. Other parameters are:\nBasic tab -&gt; Mass tolerance type (ppm), Mass tolerance MS1 and MS2 (5 ppm), Relative ab cutoff (1%) to further remove background noise.\nFormula finder -&gt; check “Lewis and Senior check”, check all elements suitable for your compounds.\nStructure finder -&gt; tree depth (2), check “Use the fragmentation library for EI”.\nFill in the information in (10) in Figure @ref(fig:MSFINDER) for your compound. For GC-MS, in most cases the monoisotopic peak (somewhat equivalent to the precursor ion in LC mode) is not present and you can choose the fragment ion closest to the monoisotopic mass as the “precursor m/z”. Then choose the precursor type. For GC-EI-MS: choose [M]+. (M plus dot). After you are done, select “Fragment annotation (single)” in the “Analysis” menu (11). Afterwards, select the “Fragment annotation (batch job)” under the same menu. The in silico annotation of the fragment ions should now be calculated (12) and you can thereafter export the annotated spectrum as an “.msp” file (see 13). Copy and paste the file name that was generated in the standard infosheet you find at the “COMMENT: msp file name” row. Save the file in the “3_MSP” subfolder.\nOpen and check the .msp file by right click and open with e.g. Notepad (dont double click as .msp is also a program installation format in Windows).\nNOTE: if you have processed other files in MS-FINDER before this (these will show in the “File navigator” tab), then these are all saved into the same msp file. You can either delete the old ones at the subfolder “MS-FINDER xxx/MSDIAL_TEMP/” before you process the standard, or you can manually delete the other compounds in the generated msp file.\nNOTE: Sometimes MSFINDER will also include peaks that have much higher m/z values than the monoisotopic peak and its isotopic peaks. This is due to interferences that MSDIAL could not deconvolute. In this case, you can open the .msp file and manually delete the rows with the m/z and intensity of these peaks. YOU NEED ALSO TO UPDATE THE Num Peaks: row in the .msp file since you have now deleted some peaks. Also make sure that there is two empty rows at the end of the .msp document.\nNow you are finished with generating the msp file for your standard spectrum.\nYou can also fill in the missing information in the infosheet: COMMENT: QUANTMASS, AC$CHROMATOGRAPHY: KOVATS_RTI and AC$CHROMATOGRAPHY: RETENTION_TIME. The COMMENT: QUANTMASS is the representative mass of the standard analyte which MSDIAL will use to quantify and compare amongst different samples. If this is not indicated then MSDIAL chooses the base peak (or the silanized peaks based on parameters choosen) and these are not always representative for the analytes. Importantly, if the monoisotopic peak is present in the spectrum at a fairly high abundance (even if it is not the highest intensity peak), then this should be chosen as the COMMENT: QUANTMASS instead of the base peak.\nSend the newly created files to Thanh:\n\nIndividual infosheet(s)\n\nmzML file(s)\n\nmsp file(s)\n\nThe mainlib excel file as well as the combined msp file will be updated on a regular basis or upon request.\nThe final msp file will look something like below (not including the ## sign). A note is that the retention index is not included by MS-FINDER when you export to msp file. This will be later automatically added to the combined database based on the retention index value in the infosheet for the specific standard (at the “AC$CHROMATOGRAPHY: KOVATS_RTI” row). Therefore, it is important to check that all files have consistent MTM IDs for the same measured compound.\n\n\nNAME: 1-Methoxy-4-(4-propylcyclohexyl)cyclohexane\nSCANNUMBER: -1\nRETENTIONTIME: 16.66233\nRETENTIONINDEX: 1815\nPRECURSORMZ: 208.20927\nPRECURSORTYPE: [M]+.\nIONMODE: Positive\nSPECTRUMTYPE: Centroid\nFORMULA: C16H30O\nINCHIKEY: JMOYCPSDEMHCFG-UHFFFAOYSA-N\nINCHI: \nSMILES: CCCC1CCC(CC1)C2CCC(CC2)OC\nAUTHORS: Wang T. et al. MTM Research Centre, Orebro University\nCOLLISIONENERGY: 70\nINSTRUMENT: Q Exactive GC Orbitrap GC-MS/MS\nINSTRUMENTTYPE: GC-EI-FT\nIONIZATION: \nLICENSE: CC BY\nCOMMENT: \nNum Peaks: 80\n55.05424    163078256\n56.05759    11327176\n57.06988    37068584\n58.04133    10225466\n59.04913    3163828\n65.03855    26553580\n66.04638    22100750\n67.05419    693562624\n68.05755    51898152\n69.06983    236269520\n70.07317    13133868\n71.04909    151444288\n72.05691    29205364\n73.06474    2747695\n77.03854    93605232\n78.04638    61790368\n79.05419    573201216\n80.062  208521232\n81.06983    1302587392\n82.06878    1987492\n82.07762    529499328\n83.08546    265512848\n84.08884    14965608\n85.10112    10732988\n91.05418    114294912\n92.06201    22463942\n93.06986    327123712\n94.07767    117894488\n95.04905    4559664\n95.08546    437583808\n96.09327    136581616\n97.10113    106149968\n98.10445    6473394\n103.05417   3832939\n105.06983   33031638\n106.07766   6479869\n107.08548   233612656\n108.09329   182412208\n109.10114   421572864\n110.10894   91032904\n111.11675   53111140\n112.0882    7177564\n113.09605   5025032\n115.05415   3284804\n117.06974   3204507\n119.08552   10350805    \"Theoretical m/z 119.086075, Mass diff 0 (0 ppm), Formula C9H11\"\n120.09335   6821262\n121.10114   307112608   \"Theoretical m/z 121.10118, Mass diff 0 (0.33 ppm), SMILES CCC1CCC(C)CC1, Annotation [C9H18-5H]+, Rule of HR True\"\n122.10893   282780416\n123.11674   393876896\n124.1246    151498160\n125.12802   22628860\n133.1012    7754902 \"Theoretical m/z 133.101725, Mass diff 0 (0 ppm), Formula C10H13\"\n134.10895   3176842 \"Theoretical m/z 134.108995, Mass diff 0 (0.34 ppm), SMILES CCC1CCC(CC)CC1, Annotation [C10H20-6H]+, Rule of HR False\"\n135.11678   219233840   \"Theoretical m/z 135.116821, Mass diff 0 (-0.31 ppm), SMILES C\\C=C\\C=C1\\CCC[C+]1C, Annotation [C10H15]+, Rule of HR True\"\n136.12462   53804344\n137.13242   38836660    \"Theoretical m/z 137.13247, Mass diff 0 (0.37 ppm), SMILES CCCC1CCC(C)CC1, Annotation [C10H20-3H]+, Rule of HR True\"\n138.14018   25185838\n139.14809   11154908    \"Theoretical m/z 139.148121, Mass diff 0 (0.22 ppm), SMILES CCCC1CCC(C)CC1, Annotation [C10H20-H]+, Rule of HR True\"\n147.11674   2291410 \"Theoretical m/z 147.117375, Mass diff 0 (0 ppm), Formula C11H15\"\n149.13238   75286480    \"Theoretical m/z 149.132476, Mass diff 0 (0.64 ppm), SMILES CCC1CCC(CC1)C(C)C, Annotation [C11H22-5H]+, Rule of HR True\"\n150.1402    29362468    \"Theoretical m/z 150.140301, Mass diff 0 (0.67 ppm), SMILES CCCC1CCC(CC)CC1, Annotation [C11H22-4H]+, Rule of HR False\"\n151.148 23773808    \"Theoretical m/z 151.148126, Mass diff 0 (0.83 ppm), SMILES CCCC1CCC(CC)CC1, Annotation [C11H22-3H]+, Rule of HR True\"\n152.1515    2928506\n161.1324    2178252 \"Theoretical m/z 161.133026, Mass diff 0 (0 ppm), Formula C12H17\"\n162.14021   5460352\n163.14796   513516864   \"Theoretical m/z 163.148126, Mass diff 0 (1.02 ppm), SMILES C1CCC(CC1)C2CCCCC2, Annotation [C12H22-3H]+, Rule of HR True\"\n164.15137   122409664\n165.15913   19514364\n166.16704   2086600\n167.1429    4521269 \"Theoretical m/z 167.143045, Mass diff 0 (0.87 ppm), SMILES O(C)C1CCC(CC1)C(C)CC, Annotation [C11H22O-3H]+, Rule of HR True\"\n177.1636    256769824   \"Theoretical m/z 177.163781, Mass diff 0 (1.02 ppm), SMILES CC1CCC(CC1)C2CCCCC2, Annotation [C13H24-3H]+, Rule of HR True\"\n178.16693   45725136\n179.17041   4097704\n180.18657   1308408\n191.1792    17871500    \"Theoretical m/z 191.179422, Mass diff 0 (1.16 ppm), SMILES CCC1CCC(CC1)C2CCCCC2, Annotation [C14H26-3H]+, Rule of HR True\"\n192.1825    2655085\n206.2027    271511328\n207.20602   42997728\n208.20927   3335620"
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_LC.html#analyze-the-standards-using-hrms",
    "href": "chapter-HRMS_Spectral_Lib_LC.html#analyze-the-standards-using-hrms",
    "title": "14  MTM HRMS Library: LC-HRMS",
    "section": "14.1 Analyze the standards using HRMS",
    "text": "14.1 Analyze the standards using HRMS\nIt is recommended to analyze single standards but mixtures are also feasible to analyze if the analytes are not coeluting too close to each other. The deconvolution algorithm of MS-DIAL is able to distinguish between two peaks that are closely eluted but still have slightly different retention times and peak shapes.\nYou should also inject a solvent blank to perform blank subtraction later in MS-DIAL."
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_LC.html#convert-the-raw-data-file-from-lc-hrms-in-unifi-to-mzml-using-msconvert",
    "href": "chapter-HRMS_Spectral_Lib_LC.html#convert-the-raw-data-file-from-lc-hrms-in-unifi-to-mzml-using-msconvert",
    "title": "14  MTM HRMS Library: LC-HRMS",
    "section": "14.2 Convert the raw data file from LC-HRMS in unifi to mzML using MSconvert",
    "text": "14.2 Convert the raw data file from LC-HRMS in unifi to mzML using MSconvert\nPlease check the steps according to @ref(MSConvertunifi)"
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_LC.html#fill-in-the-standard-infosheet",
    "href": "chapter-HRMS_Spectral_Lib_LC.html#fill-in-the-standard-infosheet",
    "title": "14  MTM HRMS Library: LC-HRMS",
    "section": "14.3 Fill in the standard infosheet",
    "text": "14.3 Fill in the standard infosheet\nIn the main folder, choose one of the standard information sheets depending on whether you used LC or GC and the ionization mode. The content of the information sheet looks slightly different depending on LC or GC. Copy the chosen infosheet to the “1_Standard_infosheets” folder. In that folder, rename the copied infosheet to the new MTM id as mentioned in previous section.\nThe infosheet is organized in accordance to the format used by Massbank Europe. A description on the Massbank record format can be found here. It is important that you do not change any of the titles in the first column in the infosheet, as the format requirement is quite strict. Also, try not to copy text from one cell to another as it might change the underlying format of the cells (if you think you made an error, copy the template and redo again).\nThe rows that are in bold are information that are mandatory to fill in.\nThe “ACCESSION” row is the MTM id.\nThe “RECORD_TITLE” will be automatically generated based on the information you filled in so you should not fill this row.\n“COMMENT: centroided mzML file name” is for internal purposes and refers to the name of the mzML file you converted and copied to the “MTM_HRMS_LIB/2_mzML_data/../” folder.\n“COMMENT: msp file name” is automatically generated and will be used later to name the msp file.\n“COMMENT: CONFIDENCE” refers to how confident you are of the identification of your standard according to the “Schymanski scale”. Leave it as “Reference Standard (Level 1)”, unless there are standards where you cannot distinguish or identify between different isomers in a standard. In this case, you should use “Level 3”. An example is “Technical mixture (Level 3)”, where we analyzed a technical standard (usually &lt;90% purity) and several isomeric peaks can be seen in the chromatogram. In this case, I usually individually register each isomer in its own infosheet.\n“CH$NAME:” occurs twice which means you have to input two different names for the compound in the standard, because a compound can have different names. It could be the common name specified in PubChem, the IUPAC name, trade name or the abbreviation.\n“CH$IUPAC” is the InChI and always starts with “InChI=”. You can find all these information for the compound by searching in PubChem.\nFor GC compounds, you also need to fill in the “AC$CHROMATOGRAPHY: KOVATS_RTI” and “AC$CHROMATOGRAPHY: RETENTION_TIME”. These will be available later in MS-DIAL.\nThe other rows should be quite straightforward to fill in. If you use the same method for many standards, then you can save a copy of an infosheet to use as a method template, while only updating information for each specific compound: ACCESSION, DATE, COMMENT: centroided mzML file name, CH$NAME, CH$NAME, CH$FORMULA, CH$EXACT_MASS:, CH$SMILES:, CH$IUPAC:, CH$LINK: CAS, CH$LINK: INCHIKEY\nThe AC$CHROMATOGRAPHY: RETENTION_TIME row will be obtained later using MS-DIAL.\nNow that you have filled in most information about the compound, we can proceed to process the mzML file to extract the spectra using MS-DIAL (although you can also first process the mzML files and then fill in the information afterwards)."
  },
  {
    "objectID": "chapter-HRMS_Spectral_Lib_LC.html#use-ms-dial-to-perform-spectral-deconvolution-and-generate-spectra-for-each-compound",
    "href": "chapter-HRMS_Spectral_Lib_LC.html#use-ms-dial-to-perform-spectral-deconvolution-and-generate-spectra-for-each-compound",
    "title": "14  MTM HRMS Library: LC-HRMS",
    "section": "14.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound",
    "text": "14.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound\nThe graphical user interface of MS-DIAL takes some time to get used to since it is centered around detected peaks. It is important that you choose the correct parameters in the beginning since the parameters can affect the peak detection and alignment, or else you need to redo the data preprocessing again which could take long time if you are analyzing a lot of samples. When you run a large number of real samples, it is recommended to first optimize the parameters using e.g. QC samples. In this case where we analyze standards, then the default parameters with some instrument specific parameters can be used. These are found in the subfolder MSDIAL_PROJECT/MSDIAL_params/. If you want to know more details about data processing using MS-DIAL, please check the MS-DIAL online tutorial.\nThe below steps are based on the workflow for GC-EI orbitrap data described by Price et al. and adapted to LC-HRMS.\nIN THIS EXAMPLE HERE, I WILL USE ONE STANDARD OF PFAS ANALYZED IN LC-ESI IN POSITIVE MODE\n1. In the File menu, start a new project. You must choose a file path where the mzML file(s) are located. When the data analysis is finished, several files associated with the analysis is created in the same folder. Depending on GC or LC analysis, then different parameters needs to be selected. Below Figure @ref(fig:LCMSDIALStartup) shows parameters for LC analysis. LC-ESI is a soft ionization and the Waters G2 XS qtof instrument uses MSe which has an alternating low energy scan and high energy scan. Choose “SWATH-MS” and then browse to the _“MSDIAL_PROJECT_params*MSe_50_1200_params.txt”* file. This specifies the parameters for the MSe experiment. Since we also centroided the mzML file for both MS1 and MSMS so these parameters needs to be specified. In this example, we ran a PFAS standard in negative mode, so this ion mode was choosen in this case.\n\n\n\n\n\nStarting a new project for LC analysis\n\n\n\n\nClick on the “Advanced: add further meta data” tab. The information for different instruments in our lab can be found in the file “/MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/Metadata.txt”. If your instrument is not present then you can input these by yourself. This metadata is optional but the information will be added to the msp file later.\nWhen you are finished, click on next.\n2. Click on the browse button and then you will select the files to process. The default file format is .abf but we want to process .mzML so choose this file format instead. You will now see the mzML file(s) in your working directory. If you want to process multiple files use Shift/Ctrl + select. Make sure your standards are designated as “Sample”. You should include a solvent blank which will be designated as “Blank”. The other columns are for post processing and not important for this spectral database workflow. You can learn more about these in the tutorial.\n\n\n\n\n\nChoosing files\n\n\n\n\nClick on next to the Analysis parameter settings.\n3. The following instructions are for Waters G2 XS qtof in ESI negative mode, but the other processing methods are similar. Below Figure @ref(fig:LCMSDIALPeakdetection) shows the parameters for the XS qtof instrument. The MS1 and MS2 tolerance was set to 0.05 Da. Click on the “Advanced” tab and check the “Consider Cl and Br elements”. You can also choose how many samples (threads) to process in parallel.\nContinue with the “Peak detection” tab and set an appropriate minimum peak height. Use the following parameters for our spectral library purpose:\nMinimum peak height: 1000 amplitude.\nMass slice width: 0.05 Da.\nThis is instrument specific and also depends on the concentration of the analytes. The advanced tab can be left as default.\n\n\n\n\n\nPeak detection parameters\n\n\n\n\nContinue to the “MS2Dec” tab.\n4. The sigma window value is an important parameter which determines the efficiency of the deconvolution algorithm. The parameter depends on the instrument and Figure @ref(fig:LCMSDIALMS2Dec) shows the recommended ones for the GC orbitrap analysis of standards. From the online tutorial: “The sigma window value is highly affected by the resolution of deconvolution. A higher value (0.7-1.0) will reduce the peak top resolutions, i.e. the number of resolved chromatographic peaks will be decreased. On the other hand, a lower value (0.1-0.3) may also recognize many noise chromatographic peaks..”\n\n\n\n\n\nMS2Dec parameters\n\n\n\n\nThe “Identification” tab is not necessary to modify for our purpose and mainly important when processing real samples (using the HRMS library as suspect list).\nGo on to the “Adduct” tab.\n__5._ The adduct should be chosen based on your knowledge of the ionization behavior of the standards. Most common is the [M-H]- ion for negative mode and [M+H]+ ion for positive mode. some compounds have much higher ion abundance for other adducts and therefore these can be included also. You also define your own adducts in the “User-defined adduct” subtab if it is not present in the list.\n\n\n\n\n\nAdduct parameters\n\n\n\n\n“Alignment” tab. The purpose of alignment is to align all individual samples so the retention times for the same for the same compound between all samples. This is because the chromatographic separation will change between runs and batches and needs to be aligned. In the “Advanced” subtab, check the “Remove features based on blank information”. A sample/blank ratio of 5 should be ok. This will remove any features that are lower than five times the blank samples (solvent blank in this case). Everything else can be as default.\nThe “Isotope tracking” tab does not need to be modified in this workflow.\nPress Finish and the process will begin. This might take some time depending on how many samples you are processing and the processing power of the computer.\nNow you are done and click on “Finish”.\nAfter the peak detection and deconvolution process is finished, you should see below screen.\n\n\n\n\n\nx\n\n\n\n\nDouble click on the sample name where your standard was analyzed (see 1 in Figure @ref(fig:LCMSDIALSample)). Your screen will be switched to the “Peak spot viewer” tab. Each detected component will be seen as a downward pointing triangle (see 2 in Figure @ref(fig:LCMSDIALSample)). You should zoom in to the peak by moving you pointer to below the x-axis and scroll to zoom in the retention time axis (3). You should now be able to see the peak more clear and click on the peak as seen in 4 in Figure @ref(fig:LCMSDIALPeak).\n\n\n\n\n\nx\n\n\n\n\nYou can then see the EIC (5) of the chosen peak to check if the peak shape is good. The extracted spectrum will be shown in (6), and the retention time and retention index can be seen in (7). This is the deconvoluted spectrum and you can see the peak shape of the ion fragments with the highest intensities by choosing the “EI chrom” tab (8) which allows you to see if the deconvolution process has been successful (9). When you feel that the quality is good, then you can export the spectrum to MS-FINDER by clicking on the “MS FINDER search” button (10).\n\n\n\n\n\nx\n\n\n\n\nIn the new MS-FINDER window, fill in the information in (10) in Figure @ref(fig:LCMSFINDER) for your compound. For GC-MS, in most cases the monoisotopic peak (somewhat equivalent to the precursor ion in LC mode) and you can choose the ion closest to the monoisotopic mass of your standard compound. Then choose the precursor type. For GC-MS: choose [M]+. (M plus dot). After you are done, select “Fragment annotation (single)” in the ““Analysis” menu (11). Afterwards, select the “Fragment annotation (batch job)” under the same menu. The in silico annotation of the fragment ions should now be calculated (12) and you can thereafter export the annotated spectrum as an “.msp” file (see 13). Use the file name that was generated in the standard infosheet you filled at the “COMMENT: msp file name” row. Save the file in the “3_MSP” subfolder.\nNow you are finished with generating the msp file for your standard spectrum.\nSend the newly created files together with the mzML files to Thanh\nThe mainlib excel file as well as the combined msp file will be updated on a regular basis or upon request.\nThe final msp file will look something like below (not including the ## sign). A note is that the retention index is not included by MS-FINDER when you export to msp file. This will be later automatically added to the combined database based on the retention index value in the infosheet for the specific standard. Therefore, it is important to check that all files have consistent MTM IDs for the same measured compound.\nNEED TO UPDATE TO LC msp"
  },
  {
    "objectID": "chapter-GC_HRMS_MSDIAL.html#all-steps",
    "href": "chapter-GC_HRMS_MSDIAL.html#all-steps",
    "title": "15  GC-(LR)HRMS raw data preprocessing with MS-DIAL",
    "section": "15.1 All steps",
    "text": "15.1 All steps\nNote (most of the steps can be used with GC-LRMS data, and will be documented here @ref(GCLRMS)\n\n\n\n\nGC HRMS workFlow\n\n\nThis tutorial will guide you through the different steps to process raw data from GC orbitrap HRMS using MS-DIAL. You should familiarize yourself with the workflow on GC-HRMS spectral library in the previous section @ref(GClib) as well as install the required software specified in the section. You should also check the online tutorial provided by the developers: https://mtbinfo-team.github.io/mtbinfo.github.io/MS-DIAL/tutorial\nYou first need to convert the .raw files from GC orbitrap HRMS to the open .mzml format using MSConvert according to @ref(MSConvertGC)."
  },
  {
    "objectID": "chapter-GC_HRMS_MSDIAL.html#post-processing",
    "href": "chapter-GC_HRMS_MSDIAL.html#post-processing",
    "title": "15  GC-(LR)HRMS raw data preprocessing with MS-DIAL",
    "section": "15.2 Post processing",
    "text": "15.2 Post processing\n\n15.2.1 Additional search against NIST library using MSPepSearch and RamSearch\nYou can export the aligned results as RIKEN msp from MS-DIAL and query this again a NIST library. Although the NIST library is recorded in low resoution unit mass, the large libary is also useful complement to the in-house HRMS library. There is two ways to query against the NIST and own library; using either the command line program MSPepSearch or the GUI software RamSearch (Broeckling et al, Anal. Chem. 2016, 88, 18, 9226–9234).\nFollow these steps:\n\nIn MS-DIAL: click “Export” -&gt; “Alignment result”. Check “Representative spectra”, “Filter by the ion abundances of blank samples” and choose “Export format” to msp and click on “Export” button.\nOpen the NIST MS Search program. Clear the results from previous search. Import the exported RIKEN msp to NIST MS Search. No need to wait until the search is finished (press abort after the import is finished). Then select all individual queries and export as msp. It has been found that Lib2NIST might not working properly for some RIKEN dataset and therefore the NIST MS Search protocol is more compatible with MSPePSearch and RamSearch.\nTo use the command line MSPepSearch, please check @ref(mspepsearch). For manual library query, it is recommended to use RamSearch. First, download the software which can be found at the supplementary information of the paper by Broeckling et al (Anal. Chem. 2016, 88, 18, 9226–9234). Install the software and follow the tutorial found in the installation folder and query against for GC-MS data. RamSearch uses MSPepSearch to query the msp files against NIST libraries. An advantage of RamSearch is the GUI which allow you to compare the query spectrum with the library spectra. Furthermore, you can also sort the hits according to the various match scores, which saves a lot of time by only look at those that have high scores.\nYou can also add own library to the NIST main folder to enable multiple library searches. To do this, follow the steps in @ref(lib2nist).\nIn order to provide more more robust quantitative comparison, you can manually set up a quantification method in Tracefinder by choosing the suspects with high identification confidence. Make a list of the quantification ion (high abundance and at high m/z, preferably the molecular ion) and 2 qualitative ions, as well as the retention time. If available, then also choose representative ions for the RS in order to reduct the variations of intensity between different samples. The integrated peaks can be used for pseudo-quantification as well as comparative statistics of quantitative ions between samples (e.g. PCA, HCA,..)."
  },
  {
    "objectID": "chapter-GC_HRMS_MSDIAL.html#further-explanation-for-some-terminologies-apart-from-the-tutorial-httpsmtbinfo-team.github.iomtbinfo.github.ioms-dialtutorial",
    "href": "chapter-GC_HRMS_MSDIAL.html#further-explanation-for-some-terminologies-apart-from-the-tutorial-httpsmtbinfo-team.github.iomtbinfo.github.ioms-dialtutorial",
    "title": "15  GC-(LR)HRMS raw data preprocessing with MS-DIAL",
    "section": "15.3 Further explanation for some terminologies apart from the tutorial (https://mtbinfo-team.github.io/mtbinfo.github.io/MS-DIAL/tutorial)",
    "text": "15.3 Further explanation for some terminologies apart from the tutorial (https://mtbinfo-team.github.io/mtbinfo.github.io/MS-DIAL/tutorial)\nGap fill: The peak less than “minimum abundance” parameter of peak detection tab will be not detected even though there is a peak, and it can be gap-filled for the alignment process if the peak having the same RT and m/z is detected in other samples.\nFrom http://www.metabolomics-forum.com/index.php?topic=1469.0:\nIn the alignment process, this program will make a master peak list (in a worst case) like:\n\nRT: 1.05 min, m/z: 100.01\n\nRT: 1.1 min, m/z: 100.015\n\nRT: 1.2 min, m/z: 100.03.\n\nThen, a peak having e.g. RT: 1.1 min and m/z: 100.02 in a file e.g. (Q) will be aligned to (B) of the master list. After that, this program will recognize that the file (Q) does not have the certain peaks for (A) and (C), and then the program will perform the gap filling method to fill the values. However, for example, when users use an RT tolerance as 0.1 min and an m/z tolerance as 0.01 Da for the alignment tolerance, newly created peak for a master list’s (A) in the file (Q) should be nearly equal to what the file (Q) has for the master peak list’s (B) because the extracted ion chromatogram for the gap fill process for peak (A) should be drawn by the tolerances of RT=1.05 min +/ 0.1 min, m/z=100.01+/- 0.01. Because of these, MS-DIAL is supposed to export very similar peak height/area values for the master peak list’s (A) and (B) in the result of file (Q). Here, (B) is recognized as “detected” and (A) is recognized as “gap-filled” although the origin of peak is the same between them. You can know the peak origins (detected or gap-filled) in the ‘peak id’ matrix from the alignment result export option where the “-1” value is described when the peak value is inserted by the gap-filled process.\nMass slice width: depending on the processing settings, sometimes we observe the same compound splitting into 2-3 different features, and we think the mass slice width (in Peak detection) may be one of the parameters driving this effect (in addition to the alignment tolerance across samples).\nHow can we properly to choose a slice width that fits our data, i.e. neither a too wide nor too narrow? For high-res Orbitrap a width of 0.05 Da is suggested. As an example, attached is an internal standard run on our LC Orbitrap (acquired at 140.000 resolution, profile).\nFrom my understanding of Tsugawa et al 2015 (Peak spotting) https://www.ncbi.nlm.nih.gov/pubmed/25938372 and the math presentation describing the MS-DIAL peak detection algorithm (default 0.1 Da), it seems MS-DIAL would correct the merging of BPCs across different m/z widths, somewhat similarly to XCMS? Below, from Smith et al 2006 (Peak detection) https://pubs.acs.org/doi/10.1021/ac051437y\n“An important detail is the relationship between spectral peak width and slice width.\n\nif the peak width is larger than slice width: the signal from a single peak may bleed across multiple slices. Low-res MS produce peak widths greater than the XMCS default 0.1 m/z slice. The MEND peak detection algorithm uses a scoring function to assess whether a chromatographic peak is also at the maximum of a spectral peak, preemptively removing such bleed. Instead of eliminating spurious extra peaks during detection, our algorithm uses a post-processing step that descends through the peak list by intensity, eliminating any peaks in the vicinity (0.7 m/z) of higher intensity peaks.\nif the peak width is smaller than the slice width: high-res TOF or Fourier transform MS often exhibit such behavior. In that case, depending on the scan-to-scan precision of the instrument, the signal from an analyte may oscillate between adjacent slices over chromatographic time, making an otherwise smooth peak shape appear jagged. Based on operator knowledge of the mass spectrometer characteristics, we optionally combine the maximum signal intensity from adjacent slices into overlapping EIBPCs (i.e., 100.0/100.1, 100.1/100.2, etc.), That initial step produces both smooth and jagged chromatographic profiles, which are then used for filtration and peak detection. During the vicinity elimination postprocessing step, peaks detected from smooth profiles (integrated from the full signal) are selected over peaks detected from jagged profiles (integrated from an incomplete signal).”\n\nwhen many duplicate peaks occurred, I recommend to do:\n1. Use larger “MS1 tolerance” of data collection tab.\n2. Use lager “Mass slice width” of peak detection tab.\n3. Use larger “Smoothing level” of peak detection tab.\n4. Use larger “Retention time tolerance” of alignment tab.\n5. Use larger “MS1 tolerance” of alignment tab.\nMore info: http://www.metabolomics-forum.com/index.php?topic=1459.msg4350#msg4350 QuantMass:\n\nFirst of all, the chromatogram deconvolution is performed by the information of “pure” extracted ion chromatogram of several m/z values.\nThe quant mass is determined from such m/z values producing the singlet/no-coeluted chromatographic peak.\n\nAt least in TMS-based GC-MS based metabolomics, m/z 147 (2xTMS moiety) becomes base peak in EI-MS spectrum for many metabolite features, and therefore, such the m/z value should not be used as the quant mass even though the m/z value is the base peak’s m/z value. Of course, the quant mass values can be changed by the quant mass manager of MS-DIAL.\nFor the data comparison in the large scaled data set, we should keep the same quant mass value for metabolite quantification. MS-DIAL offers such an environment.\n\nif you put “QUANTMASS:” field in your msp format file, the metabolite is always quantified by the target m/z.\nGo to “Quantmass browser” of “Post processing” in the msdial menu, then, you can define the m/z values for each metabolite. The first option should be used if many biological samples are sequentially analyzed for a long time.\nMore info: http://www.metabolomics-forum.com/index.php?topic=1412.0"
  },
  {
    "objectID": "chapter-GC_HRMS_MSDIAL.html#GCLRMS",
    "href": "chapter-GC_HRMS_MSDIAL.html#GCLRMS",
    "title": "15  GC-(LR)HRMS raw data preprocessing with MS-DIAL",
    "section": "15.4 GC-LRMS",
    "text": "15.4 GC-LRMS\nThis is a workflow for Agilent GC-LRMS single quandrupole .d data.\n1. If you are using old Chemstation software, you need to convert the old .d format to the Masshunter .d format.\n1.1. Download GCMS Translator from:\nhttps://www.agilent.com/en/support/software-informatics/masshunter-suite/masshunter/masshunter-software/chemstation-to-masshunter-data-file-translator\nSome supporting docs can be found here:\nhttps://www.agilent.com/en/products/software-informatics/masshunter-suite/masshunter-translators\nhttps://www.agilent.com/cs/library/support/Patches/SSBs/GCMS_Translator.html https://www.agilent.com/Library/usermanuals/Public/GCMS%20Translator%20Quick%20Start%20Guide-en.pdf\n2. Convert the new .d folders to mzML using MSConvert @ref(DataConversion)\n3. Follow the same steps of above GC-HRMS, with parameters more suitable for LRMS data."
  },
  {
    "objectID": "chapter-LC_HRMS_MSe_MSDIAL.html#some-recommended-values-for-g2-xs-qtof",
    "href": "chapter-LC_HRMS_MSe_MSDIAL.html#some-recommended-values-for-g2-xs-qtof",
    "title": "16  LC-HRMS MSe raw data preprocessing with MS-DIAL",
    "section": "16.1 Some recommended values for G2 XS qtof:",
    "text": "16.1 Some recommended values for G2 XS qtof:\nMS1 tolerance: 0.01\nMS2 tolerance: 0.01\nMaximum charge number: 2\nConsider Cl Br: Yes\nMinimum peak height: 10000\nMass slice width: 0.05\nSmoothing method: Linear weighted moving average\nSmooth level: 3\nMinimum peak width: 5\nMSMS ab cutoff: should be &gt;500 Da to get rid of noisy background peaks to the spectrum\nExlude after precursor: Yes\nKeep isotopic ions until: 8 (but varies if Cl and Br will be used for mass defect plots? Maybe higher value (10?) for negative mode?? NEED TO CHECK!!)\nKeep isotopic ions w/o MS2Dec: Yes\nCorrDec settings\nMS2 tolerance: 0.01 Da\nMin MS2 peak intensity:100 amplitude (this should be tested against individual features to optimize)\nMin number of detected samples: 3 (depends on the total number of samples, should have many samples to be efficient)\nExcl highly correlated spots: 1 (to also include precursor ion in the MS2)\nMin. corr coefficient (MS2): 0.85\nMargin 1: unsure\nMargin 2: unsure\nMin detected rate: 0.5 (default but unsure what it means, percent or fraction?)\nMin MS2 rel intensity: 2 % Remove peaks larger than precursor: Yes\nHow to export CorrDec spectra? http://www.metabolomics-forum.com/index.php?topic=1473.0"
  },
  {
    "objectID": "chapter-LC_HRMS_MSe_MSDIAL.html#post-processing",
    "href": "chapter-LC_HRMS_MSe_MSDIAL.html#post-processing",
    "title": "16  LC-HRMS MSe raw data preprocessing with MS-DIAL",
    "section": "16.2 Post processing",
    "text": "16.2 Post processing"
  },
  {
    "objectID": "chapter-LC_HRMS_MSe_MSDIAL.html#further-explanation-for-some-terminologies-apart-from-the-tutorial-httpsmtbinfo-team.github.iomtbinfo.github.ioms-dialtutorial",
    "href": "chapter-LC_HRMS_MSe_MSDIAL.html#further-explanation-for-some-terminologies-apart-from-the-tutorial-httpsmtbinfo-team.github.iomtbinfo.github.ioms-dialtutorial",
    "title": "16  LC-HRMS MSe raw data preprocessing with MS-DIAL",
    "section": "16.3 Further explanation for some terminologies apart from the tutorial (https://mtbinfo-team.github.io/mtbinfo.github.io/MS-DIAL/tutorial)",
    "text": "16.3 Further explanation for some terminologies apart from the tutorial (https://mtbinfo-team.github.io/mtbinfo.github.io/MS-DIAL/tutorial)\nGap fill: The peak less than “minimum abundance” parameter of peak detection tab will be not detected even though there is a peak, and it can be gap-filled for the alignment process if the peak having the same RT and m/z is detected in other samples.\nFrom http://www.metabolomics-forum.com/index.php?topic=1469.0:\nIn the alignment process, this program will make a master peak list (in a worst case) like:\n\nRT: 1.05 min, m/z: 100.01\n\nRT: 1.1 min, m/z: 100.015\n\nRT: 1.2 min, m/z: 100.03.\n\nThen, a peak having e.g. RT: 1.1 min and m/z: 100.02 in a file e.g. (Q) will be aligned to (B) of the master list. After that, this program will recognize that the file (Q) does not have the certain peaks for (A) and (C), and then the program will perform the gap filling method to fill the values. However, for example, when users use an RT tolerance as 0.1 min and an m/z tolerance as 0.01 Da for the alignment tolerance, newly created peak for a master list’s (A) in the file (Q) should be nearly equal to what the file (Q) has for the master peak list’s (B) because the extracted ion chromatogram for the gap fill process for peak (A) should be drawn by the tolerances of RT=1.05 min +/ 0.1 min, m/z=100.01+/- 0.01. Because of these, MS-DIAL is supposed to export very similar peak height/area values for the master peak list’s (A) and (B) in the result of file (Q). Here, (B) is recognized as “detected” and (A) is recognized as “gap-filled” although the origin of peak is the same between them. You can know the peak origins (detected or gap-filled) in the ‘peak id’ matrix from the alignment result export option where the “-1” value is described when the peak value is inserted by the gap-filled process.\nMass slice width: depending on the processing settings, sometimes we observe the same compound splitting into 2-3 different features, and we think the mass slice width (in Peak detection) may be one of the parameters driving this effect (in addition to the alignment tolerance across samples).\nHow can we properly to choose a slice width that fits our data, i.e. neither a too wide nor too narrow? For high-res Orbitrap a width of 0.05 Da is suggested. As an example, attached is an internal standard run on our LC Orbitrap (acquired at 140.000 resolution, profile).\nFrom my understanding of Tsugawa et al 2015 (Peak spotting) https://www.ncbi.nlm.nih.gov/pubmed/25938372 and the math presentation describing the MS-DIAL peak detection algorithm (default 0.1 Da), it seems MS-DIAL would correct the merging of BPCs across different m/z widths, somewhat similarly to XCMS? Below, from Smith et al 2006 (Peak detection) https://pubs.acs.org/doi/10.1021/ac051437y\n“An important detail is the relationship between spectral peak width and slice width.\n\nif the peak width is larger than slice width: the signal from a single peak may bleed across multiple slices. Low-res MS produce peak widths greater than the XMCS default 0.1 m/z slice. The MEND peak detection algorithm uses a scoring function to assess whether a chromatographic peak is also at the maximum of a spectral peak, preemptively removing such bleed. Instead of eliminating spurious extra peaks during detection, our algorithm uses a post-processing step that descends through the peak list by intensity, eliminating any peaks in the vicinity (0.7 m/z) of higher intensity peaks.\nif the peak width is smaller than the slice width: high-res TOF or Fourier transform MS often exhibit such behavior. In that case, depending on the scan-to-scan precision of the instrument, the signal from an analyte may oscillate between adjacent slices over chromatographic time, making an otherwise smooth peak shape appear jagged. Based on operator knowledge of the mass spectrometer characteristics, we optionally combine the maximum signal intensity from adjacent slices into overlapping EIBPCs (i.e., 100.0/100.1, 100.1/100.2, etc.), That initial step produces both smooth and jagged chromatographic profiles, which are then used for filtration and peak detection. During the vicinity elimination postprocessing step, peaks detected from smooth profiles (integrated from the full signal) are selected over peaks detected from jagged profiles (integrated from an incomplete signal).”\n\nwhen many duplicate peaks occurred, I recommend to do:\n1. Use larger “MS1 tolerance” of data collection tab.\n2. Use lager “Mass slice width” of peak detection tab.\n3. Use larger “Smoothing level” of peak detection tab.\n4. Use larger “Retention time tolerance” of alignment tab.\n5. Use larger “MS1 tolerance” of alignment tab.\nMore info: http://www.metabolomics-forum.com/index.php?topic=1459.msg4350#msg4350\nMSMS ab cutoff:\nQuantMass:\n\nFirst of all, the chromatogram deconvolution is performed by the information of “pure” extracted ion chromatogram of several m/z values.\nThe quant mass is determined from such m/z values producing the singlet/no-coeluted chromatographic peak.\n\nAt least in TMS-based GC-MS based metabolomics, m/z 147 (2xTMS moiety) becomes base peak in EI-MS spectrum for many metabolite features, and therefore, such the m/z value should not be used as the quant mass even though the m/z value is the base peak’s m/z value. Of course, the quant mass values can be changed by the quant mass manager of MS-DIAL.\nFor the data comparison in the large scaled data set, we should keep the same quant mass value for metabolite quantification. MS-DIAL offers such an environment.\n\nif you put “QUANTMASS:” field in your msp format file, the metabolite is always quantified by the target m/z.\nGo to “Quantmass browser” of “Post processing” in the msdial menu, then, you can define the m/z values for each metabolite. The first option should be used if many biological samples are sequentially analyzed for a long time.\nMore info: http://www.metabolomics-forum.com/index.php?topic=1412.0\n\nSigma value:"
  },
  {
    "objectID": "chapter-Ion_Mobility_HRMS.html#ion-mobility-introduction",
    "href": "chapter-Ion_Mobility_HRMS.html#ion-mobility-introduction",
    "title": "17  Ion mobility HRMS",
    "section": "17.1 Ion mobility introduction",
    "text": "17.1 Ion mobility introduction"
  },
  {
    "objectID": "chapter-Ion_Mobility_HRMS.html#recommendations-for-reporting-ion-mobility-mass-spectrometry-measurements",
    "href": "chapter-Ion_Mobility_HRMS.html#recommendations-for-reporting-ion-mobility-mass-spectrometry-measurements",
    "title": "17  Ion mobility HRMS",
    "section": "17.2 Recommendations for reporting ion mobility Mass Spectrometry measurements",
    "text": "17.2 Recommendations for reporting ion mobility Mass Spectrometry measurements\nUse recommendations from the review article: https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/10.1002/mas.21585"
  },
  {
    "objectID": "chapter-Ion_Mobility_HRMS.html#ccs-databases",
    "href": "chapter-Ion_Mobility_HRMS.html#ccs-databases",
    "title": "17  Ion mobility HRMS",
    "section": "17.3 CCS databases",
    "text": "17.3 CCS databases\n\nBaker lab: https://brcwebportal.cos.ncsu.edu/baker/\nMcLean lab: https://lab.vanderbilt.edu/mclean-group/collision-cross-section-database/"
  },
  {
    "objectID": "Appendix-GCorbitrap_Handbook.html#acquisition-parameters",
    "href": "Appendix-GCorbitrap_Handbook.html#acquisition-parameters",
    "title": "18  A handbook on GC Q Exactive orbitrap use",
    "section": "18.1 Acquisition parameters",
    "text": "18.1 Acquisition parameters\nCheck: Analytical performance of the various acquisition modes in Orbitrap MS and MS/MS. https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/full/10.1002/jms.4195\nFrom: https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/full/10.1002/rcm.8609?campaign=wolacceptedarticle Orbitrap technology is based on ion oscillation frequency measurements around a central electrode, detected on a receiver plate.26 The mass spectrum is obtained after Fourier transformation of the oscillation signal with a two-point calibration. The longer the signal acquisition time, the better is the resolution.27 During this time, ions generated in the EI source are stored in an IT, the C-TRAP. The storage of ions in the C-TRAP plays a vital role in prematurely analysing discontinuous ions produced continuously by the chromatographic separation and the ionisation source. The ions introduced into the C-TRAP lose their energy in contact with N2 at approximately 1 mTorr.26 During an acquisition in full scan mode, it is possible to set the detector with different parameters: acquisition mass range, resolution, AGC target and tune values. The tune files gather the different settings of the mass spectrometer aiming to produce the ions of the EI source, but also the different voltages applied to the lenses in the ion path from the source to the C-TRAP. It is also possible to change the value of the C-TRAP energy offset (−5 to +5 V). For this study, we used standard conditions of EI (70 eV) in order to have the ideal conditions for reproducibility of the spectra. By default, the Orbitrap system acquires data in the range m/z 50–500 at 60 000 resolution mode and 70 eV for EI. The C-TRAP tune value was set to 0 V and AGT target to 1 × 106 ions with an automatic filling limit.\n\nRecommended to have about 10-12 scans per peak."
  },
  {
    "objectID": "Appendix-GCorbitrap_Handbook.html#chemical-ionization",
    "href": "Appendix-GCorbitrap_Handbook.html#chemical-ionization",
    "title": "18  A handbook on GC Q Exactive orbitrap use",
    "section": "18.2 Chemical ionization",
    "text": "18.2 Chemical ionization\nIf the instrument is in CI mode, choose the right Calibration gas and Ionization mode (“CI”), as well as the CI gas flow (typically 1-2), gas port (Port B as of 20210429, actual CI gas flow should indicate the correct port), and gas type (likely Methane, but check the cylinder). Open the CI gas flow at 2ml/min before opening anything else (before the calibration gas, filament, MS), otherwise the flow can be unstable. Afterwards the CI can be adjusted to lower flow"
  },
  {
    "objectID": "Appendix-GCorbitrap_Handbook.html#terminologies",
    "href": "Appendix-GCorbitrap_Handbook.html#terminologies",
    "title": "18  A handbook on GC Q Exactive orbitrap use",
    "section": "18.3 Terminologies",
    "text": "18.3 Terminologies\nAutomatic Gain Control (AGC): Sets the ion injection time to maintain the optimum quantity of ions for each scan. With AGC on, the scan function consists of a prescan and an analytical scan. The split lens is used to start and stop the injection of ions into the mass analyzer. It provides a high deflection voltage most of the time so that ions are deflected into a baffle except when they are to be allowed into the C-Trap. The fast switching of the ion beam ensures the precise determination of the ion injection time that is required for AGC. This is since if too many ion are in the ion cloud going in to the orbitrap, then it will oversaturate the detector.\nChemical Ionization (CI):\nNitrogen gas: Nitrogen gas is used for the purging of the ion source when removing the ion volume. It is also used in the C-Trap, when the ions are accumulated and their energy is dampened using a bath gas (nitrogen)."
  },
  {
    "objectID": "Appendix-GCorbitrap_Handbook.html#cleaning-source",
    "href": "Appendix-GCorbitrap_Handbook.html#cleaning-source",
    "title": "18  A handbook on GC Q Exactive orbitrap use",
    "section": "18.4 Cleaning source",
    "text": "18.4 Cleaning source\nhttps://www.sisweb.com/referenc/tips/msclean.htm"
  },
  {
    "objectID": "Appendix-GCorbitrap_Handbook.html#performance-mixture",
    "href": "Appendix-GCorbitrap_Handbook.html#performance-mixture",
    "title": "18  A handbook on GC Q Exactive orbitrap use",
    "section": "18.5 Performance mixture",
    "text": "18.5 Performance mixture\n QC standard mix (100 fg OFN, 10 pg HCB, 10 pg DDT and 10 pg Endrin)\nIn NCI, OFN (100 fg) should give you around 800 000 – 1 000 000 area counts with an optimal system. This can vary based on the tune parameters and column condition.\nAlkane mix C7-C40\nOdd chain alkane mix C11-C25 to help find peaks in the C7-C40 mixture\nCheck if 4,4’-Dibromooctafluorobiphenyl can be used in PCI/NCI\nAlkane only visible in PCI so if using CI then run alkane mix in PCI even for NCI runs."
  },
  {
    "objectID": "Appendix-Reproducible_research.html#docker",
    "href": "Appendix-Reproducible_research.html#docker",
    "title": "19  Reproducible research using Docker containers and similar tools",
    "section": "Docker",
    "text": "Docker\nA list of commonly used Docker commands."
  },
  {
    "objectID": "Appendix-Reproducible_research.html#python",
    "href": "Appendix-Reproducible_research.html#python",
    "title": "19  Reproducible research using Docker containers and similar tools",
    "section": "Python",
    "text": "Python\n\nInstall Anaconda\n\n\nCreat new python environments\nhttps://www.geeksforgeeks.org/set-up-virtual-environment-for-python-using-anaconda/\n\n\nDeepresolution2\nhttps://github.com/XiaqiongFan/DeepResolution2\nhttps://www.sciencedirect.com/science/article/pii/S0039914022002119"
  },
  {
    "objectID": "Example_Dust.html#gc-orbitrap-hrms-workflow",
    "href": "Example_Dust.html#gc-orbitrap-hrms-workflow",
    "title": "20  Example workflow: indoor dust",
    "section": "20.1 GC orbitrap HRMS workflow",
    "text": "20.1 GC orbitrap HRMS workflow\nThis code uses XCMS with MF -&gt; CAMERA preprocessing used in : Stettin, D.; Poulin, R.X.; Pohnert, G. Metabolomics Benefits from Orbitrap GC–MS—Comparison of Low- and High-Resolution GC–MS. Metabolites 2020, 10, 143. See the supplementary material for original code. The code was modified here to also include retention time index and also remove zero intensity peaks after peak grouping. Additional metainformation for the msp file can also be added in the “extra” object.\n\n\nlibrary(processx)\nlibrary(xcms)\nlibrary(CAMERA)\nlibrary(metaMS)\nlibrary(dplyr)\nlibrary(stringr)\n\n#first define the working directory (folder with experimental group folders inside)\n# mzMLfiles &lt;- list.files(path = \"/home/ORUNET.ORU.SE/twg/Dioxinlab/GC-Orbitrap data/Florian/Dust NTA 20200513/mzXML/\",pattern = \".mzXML\", recursive = TRUE, full.names = TRUE)\n# Remove files containing \"Hex\", blank samples\n# mzMLfiles &lt;- mzMLfiles[-grep(\"Hex\", mzMLfiles)]\n\nsample_info &lt;- readxl::read_xlsx(\"/home/ORUNET.ORU.SE/twg/Windows_home/Dust_Florian/Sample_list_NTA_dust.xlsx\",\n                               sheet = \"Sample\")\n# filter only samples\nsample_info &lt;- sample_info %&gt;%\n  dplyr::filter(!(group %in% c(\"blank_solvent\")))\n\nmzXMLfiles &lt;- as.character(sample_info$filename)\n\npd &lt;- data.frame(sample_name = paste0(sample_info$new_codes, \".mzXML\"),\n                 class = sample_info$group,\n                 stringsAsFactors = FALSE)\n# pd &lt;- pd %&gt;% dplyr::filter(sample_group != \"IS\") %&gt;% dplyr::filter(sample_group != \"RTI\")\n\n\nmin.clustersize &lt;- 17 #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra\nuseOriginalCode(TRUE) #otherwise matchedFilter will allocate a huge amount of RAM when using step = 0.001\n\n#Refer to XCMS and CAMERA documentation for information about parameters and functions\n#These are the parameters used for high rez GC-Orbitrap data\nxs1 &lt;- xcmsSet(mzXMLfiles, \n               phenoData = pd,\n               method = \"matchedFilter\", \n               fwhm = 3, step = 0.001, \n               steps = 2, max = 1000, \n               snthresh = 3, mzdiff = 0.002)\n\nxs2 &lt;- group(xs1, method = \"density\", bw = 5, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000)\n\nxs3 &lt;- retcor(xs2, method = \"obiwarp\")\n\nxs4 &lt;- group(xs3, method = \"density\", bw = 2, mzwid = 0.6, minsamp = 1, minfrac = 0, max = 1000)\n\nxs4 &lt;- group(xs3, method = \"density\", bw = 2, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000)\n\nxs5 &lt;- fillPeaks(xs4)\n\nxs6 &lt;- xsAnnotate(xs = xs5, sample=NA, polarity = \"positive\")\n\nxs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = \"maxo\")\n\nxs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE)\n\n\npeaktable &lt;- getPeaklist(xs8, intval=\"into\")\nwrite.csv(peaktable, file = \"untreated_peaktable_MatchedFilter.csv\") #This creates a peaktable .csv file with all m/z features sorted into \"compounds\"\n\n#the following script identifies all \"compounds\" considered too small according to min.clustersize\n#you don't need to modify anything, that run the next part as is\npeaktable &lt;- getPeaklist(xs8, intval=\"maxo\")\npcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup)))\nlspectra &lt;- NULL\nextra &lt;- NULL\nsmall.clusters &lt;- NULL\nbig.clusters &lt;- NULL\nn &lt;- 1\nfor(x in pcgroups) {\n  clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)])\n  if(clustersize &lt; as.numeric(min.clustersize))\n  {\n    small.clusters &lt;- c(small.clusters, x)\n  }\n  else\n  {\n    big.clusters &lt;- c(big.clusters, x)\n    gruppe1 &lt;- peaktable[peaktable$pcgroup==x,]\n    gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))]\n    gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))]\n    decider &lt;- NULL\n    for(i in 2:ncol(gruppe1))\n    {\n      decider &lt;- c(decider, sum(gruppe1[, i]))\n    }\n    highest &lt;- which(decider==max(decider), arr.ind = TRUE)\n    gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1])\n    colnames(gruppe1) &lt;- c(\"mz\", \"int\")\n    lspectra[[n]] &lt;- gruppe1\n    n &lt;- n+1\n  }\n}\n\n# remove peaks with zero intensities\n\nlspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]})\n\n\nreduced.peaktable &lt;- getReducedPeaklist(xs8, method = \"sum\", intval = \"into\", default.adduct.info = \"maxint\", mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE)\nif(is.null(small.clusters)==FALSE) {\n  for(z in small.clusters)\n  {\n    reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ]\n  }\n}\nwrite.csv(reduced.peaktable, file = \"peaktable_MatchedFilter.csv\") #This creates a peaktable .csv file with only \"compounds\" instead of m/z features\nextra &lt;- data.frame(Name = paste(\"Unknown\", big.clusters, \"RT =\",round(reduced.peaktable$rt/60, 2) ), Class = \"Unknown\", RT = round(reduced.peaktable$rt/60, 2),  stringsAsFactors = FALSE)\n\n####KOVATS#####\n#Adding Kovats retention index to the extra obejct to write to msp\ndata &lt;- data.frame(rt = extra$RT)\nalkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25),\n                           rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77))\n\nRI &lt;- vector(length = nrow(data))\nfor (i in seq_len(nrow(data))) {\n  m &lt;- dplyr::case_when(\n  data$rt[i] &gt;= alkaneSeries$rt[1] & data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1],\n  data$rt[i] &gt;= alkaneSeries$rt[2] & data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2],\n  data$rt[i] &gt;= alkaneSeries$rt[3] & data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3],\n  data$rt[i] &gt;= alkaneSeries$rt[4] & data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4],\n  data$rt[i] &gt;= alkaneSeries$rt[5] & data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5],\n  data$rt[i] &gt;= alkaneSeries$rt[6] & data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6],\n  data$rt[i] &gt;= alkaneSeries$rt[7] & data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7]\n)\n\nn &lt;- dplyr::case_when(\n  data$rt[i] &gt;= alkaneSeries$rt[1] & data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2],\n  data$rt[i] &gt;= alkaneSeries$rt[2] & data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3],\n  data$rt[i] &gt;= alkaneSeries$rt[3] & data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4],\n  data$rt[i] &gt;= alkaneSeries$rt[4] & data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5],\n  data$rt[i] &gt;= alkaneSeries$rt[5] & data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6],\n  data$rt[i] &gt;= alkaneSeries$rt[6] & data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7],\n  data$rt[i] &gt;= alkaneSeries$rt[7] & data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8]\n)\n\n\nRI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0)\n}\n\nextra &lt;- cbind(extra, RI)\n\n######END KOVATS######\n\n# create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX)\nexport.msp &lt;- construct.msp(lspectra, extra)\n\nwrite.msp(export.msp, file = \"spectra_MatchedFilter20201030.msp\") #This creates a NIST MS Search compatible .msp file with all compound pseudospectra\n\nThis code uses XCMS with centWave. Check differences and skip first steps to combine both workflows\n\n#first define the working directory (folder with experimental group folders inside)\n# mzMLfiles &lt;- list.files(path = \"/mzXML/\",pattern = \".mzXML\", recursive = TRUE, full.names = TRUE)\n# Remove files containing \"Hex\", blank samples\n# mzMLfiles &lt;- mzMLfiles[-grep(\"Hex\", mzMLfiles)]\n\nsample_info &lt;- readxl::read_xlsx(\"Sample_list_NTA_dust.xlsx\",\n                               sheet = \"Sample_xcms\")\n# filter only samples\nsample_info &lt;- sample_info %&gt;%\n  dplyr::filter(!(group %in% c(\"blank_solvent\")))\n\npd &lt;- data.frame(sample_name = paste0(sample_info$analysis, \".mzXML\"),\n                 sample_group = sample_info$group,\n                 stringsAsFactors = FALSE)\n\nmzXMLfiles &lt;- paste0(sample_info$path, \"/\", sample_info$analysis, \".mzXML\")\n\n\n\n# Use subset to test\npd &lt;- pd[1:2,]\nmzXMLfiles &lt;- mzXMLfiles[1:2]\n\nraw_data &lt;- readMSData(mzXMLfiles, \n                         pdata = new(\"NAnnotatedDataFrame\", pd),\n                         mode = \"onDisk\")\n\n# pd &lt;- pd %&gt;% dplyr::filter(sample_group != \"IS\") %&gt;% dplyr::filter(sample_group != \"RTI\")\n\n#-----Find features----#\n\n# centWave params\ncwp &lt;- CentWaveParam(ppm = 5,\n                     peakwidth = c(3, 45),\n                     snthresh = 10,\n                     prefilter = c(1,30000),\n                     mzCenterFun = \"wMean\",\n                     integrate = 1L,\n                     mzdiff = -0.001,\n                     fitgauss = FALSE,\n                     noise = 30000,\n                     verboseColumns = FALSE)\n\n\nxs1 &lt;- findChromPeaks(mzXMLfiles, param = cwp)\n\n# use model peak to evaluate process\nrtr &lt;- c(1440, 1460)\nmzr &lt;- c(340.238, 340.242)\nchr_raw &lt;- chromatogram(mzXMLfiles, mz = mzr, rt = rtr)\nchr_mzr &lt;- chromatogram(xs1, mz = mzr, rt = rtr)\ngroup_colors &lt;- paste0(brewer.pal(3, \"Set1\")[1:2], \"60\")\nsample_colors &lt;- group_colors[xs1$sample_group]\n\n\n#----Group features 1----#\n\npdp &lt;- PeakDensityParam(\n  sampleGroups = pd$sample_group,\n  bw = 10,\n  minFraction = 0,\n  minSamples = 1,\n  binSize = 0.002,\n  maxFeatures = 1000)\n\n\nxs2 &lt;- groupChromPeaks(xs1, param = pdp)\n\n\nplotChromPeakDensity(chr_mzr, col = sample_colors, param = pdp)\n\n\n#----retention time correction----#\n\nobip &lt;- ObiwarpParam(binSize = 0.05,  # need to check optimal binSize\n                     centerSample = integer(),\n                     response = 1L,\n                     distFun = \"cor_opt\",\n                     gapInit = numeric(),\n                     gapExtend = numeric(),\n                     factorDiag = 2,\n                     factorGap = 1,\n                     localAlignment = FALSE,\n                     initPenalty = 0,\n                     subset = integer(),\n                     subsetAdjust = c(\"average\", \"previous\"))\n\nxs3 &lt;- adjustRtime(xs2, param = obip)\n\n# Get the base peak chromatograms\nbpis_adj &lt;- chromatogram(xs3, aggregationFun = \"max\", include = \"none\")\npar(mfrow = c(2, 1), mar = c(4.5, 4.2, 1, 0.5))\nplot(bpis_adj)\n# Plot also the difference of adjusted to raw retention time.\nplotAdjustedRtime(xs3)\n\npar(mfrow = c(2, 1))\n## Plot the raw data\nplot(chr_raw)\n\n## Extract the chromatogram from the adjusted object\nchr_adj &lt;- chromatogram(xs3, rt = rtr, mz = mzr)\nplot(chr_adj, peakType = \"none\")\n\n\n\n#----Group features 2----#\n# After retention time correction, the rt values are modified and additional grouping is needed.\n\npdp2 &lt;- PeakDensityParam(\n  sampleGroups = pd$sample_group,\n  bw = 5,\n  minFraction = 0,\n  minSamples = 1,\n  binSize = 0.2,\n  maxFeatures = 1000)\n\n\nxs4 &lt;- groupChromPeaks(xs3, param = pdp2)\n\nxs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr)\nplotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp2)\n\n# iteratively decrease the binSize\npdp3 &lt;- PeakDensityParam(\n  sampleGroups = pd$sample_group,\n  bw = 2,\n  minFraction = 0,\n  minSamples = 1,\n  binSize = 0.002,\n  maxFeatures = 1000)\n\nxs4 &lt;- groupChromPeaks(xs4, param = pdp3)\n\nxs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr)\nplotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp3)\n\n#----Fill missing features----#\n\n\nxs5 &lt;- fillChromPeaks(xs4)\n\n## Check missing values before filling in peaks\napply(featureValues(xs5, filled = FALSE), MARGIN = 2,\n      FUN = function(z) sum(is.na(z)))\n\n## Missing values after filling in peaks\napply(featureValues(xs5), MARGIN = 2,\n      FUN = function(z) sum(is.na(z)))\n\n\n\n#---- QC ----#\n\n# Extract chromatograms of 4 features\nfeature_chroms &lt;- featureChromatograms(xs5, features = 10000:10004)\n\nplot(feature_chroms)\n\n\nboxplot(featureValues(xs5, value=\"into\") +1, \n        #col=as.numeric(sampclass(mtbls2Set))+1, \n        log=\"y\", las=2)\n\nsdThresh &lt;- 4.0 ## Filter low-standard deviation rows for plot\ndata &lt;- log(featureValues(xs5))+1\npca.result &lt;- pca(data, nPcs=3)\nplotPcs(pca.result, type=\"loadings\", \n        #col=as.numeric(sampclass(mtbls2Set))+1\n        )\n\n\n\n\n# It is possible to use the retention time correction and grouping step in an iterative way if needed. \n# Once you perform your last adjustRtime step and thus your last grouping step, you will obtain your final peak list (i.e. final list of ions)\n\n\n#----Annotation using CAMERA----#\n\n# Since CAMERA has not yet been ported to XCMSnExp,we need to convert to xcmsSet. \n# Note that the conversion only makes sense for somple XCMSnSets, \n# without e.g. MS level filtering (where CAMERA would then extract the wrong peaks)\n\nxs6 &lt;- as(xs5, \"xcmsSet\")\n\nxs6 &lt;- xsAnnotate(xs = xs6, sample=NA, polarity = \"positive\")\n\nxs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = \"maxo\")\n\nxs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE)\n\n\n#how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra\nmin.clustersize &lt;- 20 \n\npeaktable &lt;- getPeaklist(xs8, intval=\"into\")\nwrite.csv(peaktable, file = \"test_peaktable.csv\") #This creates a peaktable .csv file with all m/z features sorted into \"compounds\"\n\n#the following script identifies all \"compounds\" considered too small according to min.clustersize\npeaktable &lt;- getPeaklist(xs8, intval=\"maxo\")\n\n# Replaces NA in intensities with zero\npeaktable &lt;- peaktable %&gt;%\n  dplyr::mutate(dplyr::across(dplyr::starts_with(\"X\"), ~tidyr::replace_na(., 0)))\n\n\npcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup)))\nlspectra &lt;- NULL\nextra &lt;- NULL\nsmall.clusters &lt;- NULL\nbig.clusters &lt;- NULL\nn &lt;- 1\nfor(x in seq_along(pcgroups)) {\n  clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)])\n  if(clustersize &lt; as.numeric(min.clustersize))\n  {\n    small.clusters &lt;- c(small.clusters, x)\n  }\n  else\n  {\n    big.clusters &lt;- c(big.clusters, x)\n    gruppe1 &lt;- peaktable[peaktable$pcgroup==x,]\n    gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))]\n    gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))]\n    decider &lt;- NULL\n    \n    for(i in 2:ncol(gruppe1))\n    {\n      decider &lt;- c(decider, sum(gruppe1[, i]))\n    }\n    highest &lt;- which(decider==max(decider), arr.ind = TRUE)\n    gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1])\n    colnames(gruppe1) &lt;- c(\"mz\", \"int\")\n    lspectra[[n]] &lt;- gruppe1\n    n &lt;- n+1\n  }\n}\n\n\n# remove peaks with zero intensities\nlspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]})\n\nreduced.peaktable &lt;- getReducedPeaklist(xs8, method = \"sum\", intval = \"into\", default.adduct.info = \"maxint\", mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE)\nif(is.null(small.clusters)==FALSE) {\n  for(z in small.clusters)\n  {\n    reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ]\n  }\n}\nwrite.csv(reduced.peaktable, file = \"test_peaktable.csv\") #This creates a peaktable .csv file with only \"compounds\" instead of m/z features\n\nextra &lt;- data.frame(Name = paste(\"Unknown\", big.clusters, \"RT =\",round(reduced.peaktable$rt/60, 2) ), Class = \"Unknown\", RT = round(reduced.peaktable$rt/60, 2),  stringsAsFactors = FALSE)\n\n####KOVATS#####\n#Adding Kovats retention index to the extra obejct to write to msp\ndata &lt;- data.frame(rt = extra$RT)\nalkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25),\n                           rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77))\n\nRI &lt;- vector(length = nrow(data))\nfor (i in seq_len(nrow(data))) {\n  m &lt;- dplyr::case_when(\n  data$rt[i] &gt;= alkaneSeries$rt[1] & data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1],\n  data$rt[i] &gt;= alkaneSeries$rt[2] & data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2],\n  data$rt[i] &gt;= alkaneSeries$rt[3] & data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3],\n  data$rt[i] &gt;= alkaneSeries$rt[4] & data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4],\n  data$rt[i] &gt;= alkaneSeries$rt[5] & data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5],\n  data$rt[i] &gt;= alkaneSeries$rt[6] & data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6],\n  data$rt[i] &gt;= alkaneSeries$rt[7] & data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7]\n)\n\nn &lt;- dplyr::case_when(\n  data$rt[i] &gt;= alkaneSeries$rt[1] & data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2],\n  data$rt[i] &gt;= alkaneSeries$rt[2] & data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3],\n  data$rt[i] &gt;= alkaneSeries$rt[3] & data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4],\n  data$rt[i] &gt;= alkaneSeries$rt[4] & data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5],\n  data$rt[i] &gt;= alkaneSeries$rt[5] & data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6],\n  data$rt[i] &gt;= alkaneSeries$rt[6] & data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7],\n  data$rt[i] &gt;= alkaneSeries$rt[7] & data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8]\n)\n\n\nRI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0)\n}\n\nextra &lt;- cbind(extra, RI)\n\n######END KOVATS######\n\n# create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX)\nexport.msp &lt;- construct.msp(lspectra, extra)\n\nwrite.msp(export.msp, file = \"test_spectra.msp\") #This creates a NIST MS Search compatible .msp file with all compound pseudospectra"
  },
  {
    "objectID": "Example_Dust.html#lc-hrms-using-waters-mse-dia-workflow",
    "href": "Example_Dust.html#lc-hrms-using-waters-mse-dia-workflow",
    "title": "20  Example workflow: indoor dust",
    "section": "20.2 LC-HRMS using Waters MSe DIA workflow",
    "text": "20.2 LC-HRMS using Waters MSe DIA workflow"
  },
  {
    "objectID": "Example_Dust.html#workflow-for-centroiding-of-raw-file-peak-picking-and-correlation-of-ms1-and-ms2",
    "href": "Example_Dust.html#workflow-for-centroiding-of-raw-file-peak-picking-and-correlation-of-ms1-and-ms2",
    "title": "20  Example workflow: indoor dust",
    "section": "20.3 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2",
    "text": "20.3 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2"
  },
  {
    "objectID": "Example_Dust.html#first-convert-unifi-data-using-msconvert",
    "href": "Example_Dust.html#first-convert-unifi-data-using-msconvert",
    "title": "20  Example workflow: indoor dust",
    "section": "20.4 First convert unifi data using MSConvert",
    "text": "20.4 First convert unifi data using MSConvert\nOptions: output format: mzML\nbinary encoding precision: 64-bit\nWrite index: check\nTPP compatibility: check\nuse zlib compression: uncheck\npackage in gzip: uncheck\nFilters:\n1. TitleMaker\n2. msLevel: 1-2 (need to click “Add” to add filter)"
  },
  {
    "objectID": "Example_Dust.html#centroiding-raw-data-from-mzml-using-msnbase",
    "href": "Example_Dust.html#centroiding-raw-data-from-mzml-using-msnbase",
    "title": "20  Example workflow: indoor dust",
    "section": "20.5 Centroiding raw data from mzML using MSnbase",
    "text": "20.5 Centroiding raw data from mzML using MSnbase"
  },
  {
    "objectID": "Example_PFASs.html",
    "href": "Example_PFASs.html",
    "title": "21  Example workflow: PFASs",
    "section": "",
    "text": "library(DiagrammeR)\n\nA walkthrough for PFAS analysis\n\n\n\n\n\nWorkflow for nontarget using XX"
  },
  {
    "objectID": "Example-GC-LRMS_nontarget.html",
    "href": "Example-GC-LRMS_nontarget.html",
    "title": "22  GC coupled with LRMS nontarget",
    "section": "",
    "text": "Agilent Chemstation Data If using old Chemstation .d folders, then these should be converted to Masshunter .d files.\nUse the GC MSD translator software: https://www.agilent.com/en/support/software-informatics/masshunter-suite/masshunter/masshunter-software/chemstation-to-masshunter-data-file-translator.\n\nConvert the folders to Masshunter .d files\nConvert the .d files to mzml using MSConvert\nUse the mzml with MSDIAL"
  }
]